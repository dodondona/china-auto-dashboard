#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
vlm_rank_reader.py
URL からのフルページスクショ取得（Playwright）→ VLM（AI目視）で「順位/車名/台数」を抽出 → CSV に出力。

- OCRは使いません。人の“目視”に近い Vision-Language Model (VLM) を使って表から値を読み取ります。
- OpenAI (gpt-4o-mini 推奨) を標準、Gemini も選択可。
- --from-url でURLを渡すと、全自動でスクショ→抽出→CSVまで行います。
- 既存の tiles/*.png を直接読ませることも可能 (--input)。
"""

import os, io, re, glob, csv, time, json, argparse, asyncio
from pathlib import Path

# ==============================
# 引数処理
# ==============================
def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("--from-url", help="対象URL (例: https://www.autohome.com.cn/rank/1-3-1071-x/2025-08.html)")
    p.add_argument("--input", help="tiles/*.png など既存画像を直接読み込む場合")
    p.add_argument("--out", default="result.csv", help="出力CSVファイル")
    p.add_argument("--tile-height", type=int, default=1200, help="フルスクリーンを分割する高さ(px)")
    p.add_argument("--tile-overlap", type=int, default=200, help="タイル間の重なり(px)")
    p.add_argument("--fullpage-split", action="store_true", help="フルページを分割してキャプチャ")
    return p.parse_args()

# ==============================
# Playwrightでスクショ
# ==============================
async def capture_tiles(url, tile_height=1200, overlap=200):
    from playwright.async_api import async_playwright
    tiles_dir = Path("tiles")
    tiles_dir.mkdir(exist_ok=True)
    for f in tiles_dir.glob("*.*"):
        f.unlink()

    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page(viewport={"width": 1280, "height": tile_height})
        await page.goto(url, timeout=60000)
        await page.wait_for_timeout(3000)

        full_height = await page.evaluate("document.body.scrollHeight")
        n_tiles = (full_height // (tile_height - overlap)) + 1

        for i in range(n_tiles):
            y = i * (tile_height - overlap)
            await page.evaluate(f"window.scrollTo(0, {y})")
            await page.wait_for_timeout(500)
            file = tiles_dir / f"tile_{i:02d}.png"
            await page.screenshot(path=str(file), full_page=False)
            print(f"[screenshot] {file}")

        await browser.close()

# ==============================
# VLM呼び出し
# ==============================
def call_vlm(image_path):
    """
    単一画像から順位/モデル名/台数を抽出する
    """
    from openai import OpenAI
    client = OpenAI()

    prompt = """以下の自動車販売ランキング表から、順位/車名/台数 を正確に抜き出してください。
CSV形式で rank,model,sales として返してください。
"""

    with open(image_path, "rb") as f:
        img_bytes = f.read()

    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "あなたは画像からテーブルを読み取るアシスタントです。"},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": f"data:image/png;base64,{img_bytes.hex()}"}
                ],
            },
        ],
        temperature=0,
    )

    text = resp.choices[0].message.content.strip()
    rows = []
    for line in text.splitlines():
        parts = [c.strip() for c in line.split(",")]
        if len(parts) >= 3 and parts[0].isdigit():
            try:
                rows.append({
                    "rank": int(parts[0]),
                    "model": parts[1],
                    "sales": int(parts[2].replace(",", "")),
                })
            except Exception:
                continue
    return rows

# ==============================
# メイン処理
# ==============================
def main():
    args = parse_args()

    # スクショ実行
    if args.from_url:
        asyncio.run(capture_tiles(args.from_url, args.tile_height, args.tile_overlap))

    # 入力画像
    inputs = []
    if args.input:
        inputs = sorted(glob.glob(args.input))
    else:
        inputs = sorted(glob.glob("tiles/*.png"))

    all_rows = []
    for f in inputs:
        rows = call_vlm(f)
        print(f"[parsed] {f}: {len(rows)} rows")
        all_rows.extend(rows)

    # --- 重複削除 ---
    deduped = []
    seen = set()
    for row in all_rows:
        key = (row["rank"], row["model"])
        if key in seen:
            continue
        seen.add(key)
        deduped.append(row)

    # rank順に並べ替え
    deduped.sort(key=lambda r: r["rank"])

    # CSV書き出し
    out_file = Path(args.out)
    out_file.parent.mkdir(parents=True, exist_ok=True)
    with open(out_file, "w", newline="", encoding="utf-8-sig") as f:
        w = csv.writer(f)
        w.writerow(["rank", "model", "sales"])
        for r in deduped:
            w.writerow([r["rank"], r["model"], r["sales"]])
    print(f"[done] {out_file} ({len(deduped)} rows)")

if __name__ == "__main__":
    main()
