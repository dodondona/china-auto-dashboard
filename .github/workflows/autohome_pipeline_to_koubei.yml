name: autohome_pipeline_to_koubei

on:
  workflow_run:
    workflows: ["autohome_pipeline"]
    types: [completed]

permissions:
  contents: write

jobs:
  prepare_series_from_pipeline:
    if: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    outputs:
      series: ${{ steps.mkjson.outputs.series }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install tools (jq, unzip, curl)
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y jq unzip curl gh

      - name: Wait for upstream artifacts to be ready
        run: |
          echo "Waiting 60 seconds for autohome-series-urls to finalize..."
          sleep 60

      - name: Download artifact (autohome-series-urls)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          mkdir -p artifact
          gh run download ${{ github.event.workflow_run.id }} \
            --name autohome-series-urls \
            --dir artifact \
            --repo "${{ github.repository }}"
          echo "Downloaded files under artifact/:"
          ls -R artifact || true

      - name: Make JSON array of series IDs
        id: mkjson
        run: |
          set -euo pipefail
          src="artifact/series_ids.txt"
          if [ ! -f "$src" ]; then
            echo "series_ids.txt not found directly under artifact/, trying fallback..."
            src=$(find artifact -type f -name "series_ids.txt" | head -n 1 || true)
          fi
          if [ -z "${src:-}" ] || [ ! -f "$src" ]; then
            echo "series_ids.txt not found anywhere under artifact/"
            exit 1
          fi
          echo "Top of series IDs:"
          head -n 10 "$src" || true
          json=$(awk 'NF>0' "$src" | sed 's/[^0-9]//g' | awk 'NF>0' | jq -R -s -c 'split("\n")|map(select(length>0))')
          echo "series=$json" >> "$GITHUB_OUTPUT"

  koubei_from_pipeline:
    needs: prepare_series_from_pipeline
    if: ${{ needs.prepare_series_from_pipeline.outputs.series != '' }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 6
      matrix:
        series: ${{ fromJSON(needs.prepare_series_from_pipeline.outputs.series) }}

    env:
      SERIES_ID: ${{ matrix.series }}
      MIN_DIFF: "3"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true
          fetch-depth: 0

      - name: Restore koubei cache
        uses: actions/cache/restore@v4
        with:
          path: cache/
          key: koubei-cache-${{ matrix.series }}-${{ github.run_id }}
          restore-keys: |
            koubei-cache-${{ matrix.series }}-
            koubei-cache-

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          set -e
          python -m pip install --upgrade pip
          pip install playwright beautifulsoup4 lxml requests pandas openai
          python -m playwright install chromium || true

      - name: Fetch Koubei detail pages
        run: |
          set -e
          python tools/koubei_summary_playwright.py "${{ matrix.series }}" "5"
          test -s "autohome_reviews_${{ matrix.series }}.zip"

      - name: Convert ZIP to CSV
        run: |
          set -e
          python tools/koubei_summary_to_csv.py "autohome_reviews_${{ matrix.series }}.zip"
          test -s "autohome_reviews_${{ matrix.series }}.csv"

      - name: Translate CSV columns (to generate _ja columns)
        run: |
          set -e
          python tools/translate_columns.py "autohome_reviews_${{ matrix.series }}.csv"

      - name: Decide whether to (re)generate story by diff
        id: diffguard
        run: |
          set -e
          python tools/koubei_review_diff.py --min-diff "${MIN_DIFF}"

      - name: Generate story with LLM
        if: ${{ steps.diffguard.outputs.do_story == 'true' }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          set -e
          python tools/koubei_storywriter.py "${{ matrix.series }}"
          test -s "output/koubei/${{ matrix.series }}/story.txt"
          test -s "output/koubei/${{ matrix.series }}/story.md"
          mkdir -p "cache/${{ matrix.series }}"
          cp "output/koubei/${{ matrix.series }}/story.txt" "cache/${{ matrix.series }}/story.txt"

      - name: Ensure story when skipped (reuse cache or generate once)
        if: ${{ steps.diffguard.outputs.do_story == 'false' }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          set -e
          ID="${{ matrix.series }}"
          if [ -s "cache/${ID}/story.txt" ]; then
            mkdir -p "output/koubei/${ID}"
            cp "cache/${ID}/story.txt" "output/koubei/${ID}/story.txt"
            cp "cache/${ID}/story.txt" "output/koubei/${ID}/story.md"
          else
            echo "No cached story for ${ID}; generating once to seed cache."
            python tools/koubei_storywriter.py "${ID}"
            test -s "output/koubei/${ID}/story.txt"
            test -s "output/koubei/${ID}/story.md"
            mkdir -p "cache/${ID}"
            cp "output/koubei/${ID}/story.txt" "cache/${ID}/story.txt"
          fi

      - name: Sanity check outputs
        run: |
          set -e
          ID="${{ matrix.series }}"
          ls -lh autohome_reviews_${ID}.zip autohome_reviews_${ID}.csv || true
          ls -lh output/koubei/${ID}/story.txt output/koubei/${ID}/story.md || true
          wc -l autohome_reviews_${ID}.csv || true
          wc -c output/koubei/${ID}/story.txt output/koubei/${ID}/story.md || true
