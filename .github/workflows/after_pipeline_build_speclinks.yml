name: after_pipeline_build_speclinks

on:
  workflow_run:
    workflows: ["autohome_pipeline"]  # ← 前段WFの name と完全一致させる
    types: [completed]

permissions:
  contents: read
  actions: read

jobs:
  build-spec-links:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      # ★ 前段 run の「全アーティファクト」をDL（name を指定しない）
      - name: Download ALL artifacts from pipeline run
        uses: actions/download-artifact@v4
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}
          path: artifacts/pipeline

      - name: Show downloaded files
        run: |
          set -eux
          ls -lahR artifacts/pipeline || true
          find artifacts/pipeline -type f -name '*.csv' -print || true

      # 実データのランキングCSVを探して spec_links.csv を生成（列名ゆれに耐性）
      - name: Build spec_links.csv from downloaded CSVs
        shell: python
        run: |
          import csv, re
          from pathlib import Path

          root = Path("artifacts/pipeline")
          preferred = [
            "public/autohome_ranking_with_image_urls_with_maker_with_maker_ja.csv",
            "public/autohome_ranking_with_image_urls_with_maker.csv",
            "public/autohome_ranking_with_image_urls.csv",
          ]

          csv_path = None
          for rel in preferred:
            p = root / rel
            if p.exists():
              csv_path = p
              break
          if csv_path is None:
            all_csvs = sorted(root.rglob("*.csv"))
            if all_csvs:
              csv_path = all_csvs[0]
          if csv_path is None:
            raise SystemExit("ERROR: No CSV found under artifacts/pipeline")

          print(f"USING: {csv_path}")

          rows = []
          with csv_path.open("r", encoding="utf-8") as f:
            rdr = csv.DictReader(f)
            for i, r in enumerate(rdr, start=1):
              rk = (r.get("rank") or r.get("順位") or r.get("ranking") or "").strip() or str(i)
              m_rk = re.search(r"\d+", rk)
              rank = int(m_rk.group()) if m_rk else i

              sid = (r.get("series_id") or r.get("seriesId") or r.get("id") or "").strip()
              series_url = (r.get("series_url") or r.get("url") or r.get("seriesUrl") or r.get("detail_url") or "").strip()
              if not sid and series_url:
                m_sid = re.search(r"/series/(\\d+)", series_url)
                if m_sid:
                  sid = m_sid.group(1)
              if not sid:
                continue

              spec_url = f"https://www.autohome.com.cn/config/series/{sid}.html#pvareaid=3454437"
              rows.append({"rank": rank, "series_id": sid, "spec_url": spec_url})

          rows.sort(key=lambda x: x["rank"])

          out = Path("public")
          out.mkdir(parents=True, exist_ok=True)
          out_csv = out / "spec_links.csv"
          with out_csv.open("w", newline="", encoding="utf-8") as g:
            w = csv.DictWriter(g, fieldnames=["rank","series_id","spec_url"])
            w.writeheader()
            w.writerows(rows)
          print(f"WROTE {len(rows)} rows to {out_csv}")

      - name: Upload spec-link artifact
        uses: actions/upload-artifact@v4
        with:
          name: spec_links
          path: public/spec_links.csv
