name: after_pipeline_build_speclinks

on:
  workflow_run:
    workflows: ["autohome_pipeline"]  # ← 前段WFの name と完全一致させる
    types: [completed]

permissions:
  contents: read
  actions: read

jobs:
  build-spec-links:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      # 前段 run の「全アーティファクト」をDL（name を指定しない：名ズレ地獄を回避）
      - name: Download ALL artifacts from pipeline run
        uses: actions/download-artifact@v4
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}
          path: artifacts/pipeline

      - name: Show downloaded files
        run: |
          set -eux
          ls -lahR artifacts/pipeline || true
          find artifacts/pipeline -type f -name '*.csv' -print || true

      # ランキングCSV → spec_links.csv を生成
      # ・列名ゆれ対応：rank / link を優先、series_id があれば使用
      # ・link は「/12345 」「https://www.autohome.com.cn/12345」を想定（/series/12345 ではない）
      - name: Build spec_links.csv from downloaded CSVs
        shell: python
        run: |
          import csv, re, sys, itertools
          from pathlib import Path

          root = Path("artifacts/pipeline")
          preferred = [
            "public/autohome_ranking_with_image_urls_with_maker_with_maker_ja.csv",
            "public/autohome_ranking_with_image_urls_with_maker.csv",
            "public/autohome_ranking_with_image_urls.csv",
          ]

          # 1) 使うCSVを決定
          csv_path = None
          for rel in preferred:
            p = root / rel
            if p.exists():
              csv_path = p
              break
          if csv_path is None:
            all_csvs = sorted(root.rglob("*.csv"))
            if all_csvs:
              csv_path = all_csvs[0]
          if csv_path is None:
            print("ERROR: No CSV found under artifacts/pipeline", file=sys.stderr)
            sys.exit(11)

          print(f"USING: {csv_path}")

          # 2) 中身を読んで spec_links を構築
          rows = []
          with csv_path.open("r", encoding="utf-8") as f:
            rdr = csv.DictReader(f)
            headers = rdr.fieldnames or []
            print("HEADERS:", headers)

            for i, r in enumerate(rdr, start=1):
              # rank
              rk = (r.get("rank") or r.get("順位") or r.get("ranking") or "").strip() or str(i)
              m_rk = re.search(r"\d+", rk)
              rank = int(m_rk.group()) if m_rk else i

              # series_id があれば最優先
              sid = (r.get("series_id") or r.get("seriesId") or r.get("id") or "").strip()

              # link から補完（/12345 or https://www.autohome.com.cn/12345）
              link = (r.get("link") or r.get("url") or "").strip()
              if not sid and link:
                m = re.search(r"/(\d{3,6})/?$", link)
                if m:
                  sid = m.group(1)

              # series_url 系から補完（将来の互換）
              if not sid:
                series_url = (r.get("series_url") or r.get("seriesUrl") or r.get("detail_url") or "").strip()
                if series_url:
                  m2 = re.search(r"/(\d{3,6})/?$", series_url) or re.search(r"/series/(\d+)", series_url)
                  if m2:
                    sid = m2.group(1)

              if not sid:
                continue

              spec_url = f"https://www.autohome.com.cn/config/series/{sid}.html#pvareaid=3454437"
              rows.append({"rank": rank, "series_id": sid, "spec_url": spec_url})

          if not rows:
            print("ERROR: Built 0 rows for spec_links.csv", file=sys.stderr)
            # デバッグのためCSV先頭20行を表示
            with csv_path.open("r", encoding="utf-8") as f:
              head20 = list(itertools.islice(f, 20))
            print("CSV HEAD (first 20 lines):")
            for line in head20:
              print(line.rstrip("\n"))
            sys.exit(12)

          rows.sort(key=lambda x: x["rank"])
          out = Path("public")
          out.mkdir(parents=True, exist_ok=True)
          out_csv = out / "spec_links.csv"
          with out_csv.open("w", newline="", encoding="utf-8") as g:
            w = csv.DictWriter(g, fieldnames=["rank","series_id","spec_url"])
            w.writeheader()
            w.writerows(rows)
          print(f"WROTE {len(rows)} rows to {out_csv}")

      - name: Upload spec-link artifact
        uses: actions/upload-artifact@v4
        with:
          name: spec_links
          path: public/spec_links.csv
