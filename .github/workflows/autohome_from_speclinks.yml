name: autohome_from_speclinks

on:
  workflow_dispatch:
    inputs:
      spec_run_id:
        description: "Run ID that produced the spec_links artifact (from after_pipeline_build_speclinks)"
        required: true
        type: string

permissions:
  contents: read
  actions: read

jobs:
  from-spec-links:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps (minimal)
        run: |
          set -eux
          python -m pip install --upgrade pip
          pip install beautifulsoup4 lxml pandas playwright
          python -m playwright install chromium
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Download spec_links artifact
        uses: actions/download-artifact@v4
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.inputs.spec_run_id }}
          name: spec_links
          path: artifacts/spec_links

      - name: Show spec_links head
        run: |
          set -eux
          test -f artifacts/spec_links/spec_links.csv
          head -n 20 artifacts/spec_links/spec_links.csv || true

      # ヒアドキュメントを避け、Pythonシェルで実行（YAMLが壊れない）
      - name: Normalize spec_links to JSONL
        shell: python
        run: |
          import csv, json, re
          from pathlib import Path

          p = Path("artifacts/spec_links/spec_links.csv")
          rows = []
          with p.open("r", encoding="utf-8") as f:
              rdr = csv.DictReader(f)
              for i, r in enumerate(rdr, start=1):
                  sid = (r.get("series_id") or r.get("seriesId") or r.get("id") or r.get("series") or "").strip()
                  surl = (r.get("spec_url")  or r.get("url")      or r.get("specUrl")  or "").strip()
                  rk   = (r.get("rank")      or r.get("順位")      or r.get("rank_index") or "").strip()
                  if not rk:
                      rk = str(i)
                  m = re.search(r"\d+", rk)
                  rank_int = int(m.group()) if m else i
                  if surl:
                      rows.append({"rank": rank_int, "series_id": sid, "spec_url": surl})

          rows.sort(key=lambda x: x["rank"])
          with open("spec_links.jsonl", "w", encoding="utf-8") as g:
              for obj in rows:
                  g.write(json.dumps(obj, ensure_ascii=False) + "\n")
          print(f"WROTE {len(rows)} lines to spec_links.jsonl")

      - name: Run autohome_config_to_csv per link (ranked)
        run: |
          set -eux
          mkdir -p public/config_csv

          while IFS= read -r line; do
            [ -z "$line" ] && continue

            rank=$(printf '%s\n' "$line" | jq -r '.rank')
            series_id=$(printf '%s\n' "$line" | jq -r '.series_id')
            spec_url=$(printf '%s\n' "$line" | jq -r '.spec_url')

            printf -v rank3 "%03d" "$rank"
            base="${rank3}"
            if [ -n "$series_id" ] && [ "$series_id" != "null" ]; then
              base="${rank3}_${series_id}"
            fi
            outfile="public/config_csv/${base}.csv"

            echo "::group::[${rank3}] ${series_id} -> ${spec_url}"
            # --series が必須のため付与（余計な変更なし）
            python tools/autohome_config_to_csv.py --series "${series_id}"

            # 出力ファイルを拾ってリネーム保存（あなたのスクリプトに合わせてこのままでOK）
            latest=$(ls -1t public/*.csv tools/*.csv 2>/dev/null | head -n 1 || true)
            if [ -n "${latest}" ]; then
              cp -f "${latest}" "${outfile}"
            elif [ -f "public/autohome_config.csv" ]; then
              cp -f "public/autohome_config.csv" "${outfile}"
            else
              echo "key,value" > "${outfile}"
              echo "error,no_output_detected" >> "${outfile}"
            fi
            echo "::endgroup::"
          done < spec_links.jsonl

      - uses: actions/upload-artifact@v4
        with:
          name: config_csv_ranked
          path: public/config_csv/*.csv
