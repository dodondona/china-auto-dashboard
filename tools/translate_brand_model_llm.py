#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
translate_brand_model_llm.py
ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»è»Šç¨®åã‚’ LLM ã§ã‚°ãƒ­ãƒ¼ãƒãƒ«åï¼ˆè‹±èª or æ—¥æœ¬èªæ¼¢å­—ï¼‹ãƒ”ãƒ³ã‚¤ãƒ³ï¼‰ã«ç¿»è¨³ã™ã‚‹ã€‚

å¤‰æ›´ç‚¹ï¼š
- ChatGPTæœ¬ä½“ã¨åŒç­‰ã®ç†è§£åŠ›ã§ã€å…¬å¼â†’Autohomeâ†’Wikipediaâ†’Fallbackã®é †ã«æ¨å®šã€‚
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯æ¯å›å‰Šé™¤ã€‚
"""

import os
import csv
import json
import time
from openai import OpenAI

# ======= è¨­å®š =======
INPUT_CSV = "data/autohome_raw_2025-08.csv"
OUTPUT_CSV = "data/autohome_raw_2025-08_with_brand_ja.csv"
CACHE_FILE = "cache/translate_cache.json"
MODEL = "gpt-4o-mini"
SLEEP_SEC = 2.0
# ====================

client = OpenAI()

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤
if os.path.exists(CACHE_FILE):
    os.remove(CACHE_FILE)
    print("ğŸ—‘ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

# ç¿»è¨³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
PROMPT_TEMPLATE = """
ChatGPTæœ¬ä½“ã¨åŒç­‰ã®ç†è§£åŠ›ã§ã€ä»¥ä¸‹ã®ä¸­å›½èªãƒ–ãƒ©ãƒ³ãƒ‰åã¨è»Šç¨®åã‚’ã€
ã§ãã‚‹é™ã‚Šã‚°ãƒ­ãƒ¼ãƒãƒ«è²©å£²åï¼ˆè‹±èªï¼‰ã¾ãŸã¯æ—¥æœ¬èªã§ã®æ­£å¼åç§°ã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

å„ªå…ˆé †ä½ï¼š
1ï¸âƒ£ ãƒ¡ãƒ¼ã‚«ãƒ¼å…¬å¼ã®è‹±èªã‚µã‚¤ãƒˆï¼ˆBYD, Geely, Changan, XPeng, NIO, Great Wall, SAICãªã©ï¼‰ã«è¨˜è¼‰ã®è‹±èªåã‚’æœ€å„ªå…ˆã€‚
2ï¸âƒ£ æ¬¡ã«ã€Autohomeï¼ˆæ±½è½¦ä¹‹å®¶ï¼‰ã¾ãŸã¯Global Autohomeã«è¨˜è¼‰ã®è‹±èªè¡¨è¨˜ã‚’å‚ç…§ã€‚
3ï¸âƒ£ ãã‚Œã§ã‚‚å­˜åœ¨ã—ãªã„å ´åˆã¯ã€Wikipediaè‹±èªç‰ˆãƒ»æ—¥æœ¬èªç‰ˆã®è¨˜è¼‰ã‚’å‚è€ƒã€‚
4ï¸âƒ£ ã„ãšã‚Œã«ã‚‚å­˜åœ¨ã—ãªã„å ´åˆã¯ã€ä¸­å›½èªåã‚’æ—¥æœ¬èªæ¼¢å­—ã«å¤‰æ›ã—ã€æ‹¬å¼§å†…ã«ãƒ”ãƒ³ã‚¤ãƒ³ã‚’ä½µè¨˜ã—ã¦ãã ã•ã„ã€‚
   ä¾‹ï¼šå®å…‰ â†’ å®å…‰ï¼ˆHongguangï¼‰MINIEV

ãƒ–ãƒ©ãƒ³ãƒ‰åã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ–ãƒ©ãƒ³ãƒ‰è¡¨è¨˜ï¼ˆä¾‹ï¼šæ¯”äºšè¿ªâ†’BYDã€æ—¥äº§â†’æ—¥ç”£ã€ä¸°ç”°â†’ãƒˆãƒ¨ã‚¿ã€äº”è±æ±½è½¦â†’Wulingï¼‰ã€‚
è»Šç¨®åã¯å®Ÿéš›ã®è¼¸å‡ºãƒ¢ãƒ‡ãƒ«åã‚’å„ªå…ˆã—ã€ç•¥èªã§ã¯è¿”ã•ãªã„ã§ãã ã•ã„ã€‚

å‡ºåŠ›ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã§è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "brand_ja": "<ãƒ–ãƒ©ãƒ³ãƒ‰ã®æ—¥æœ¬èªã¾ãŸã¯è‹±èªè¡¨è¨˜>",
  "model_ja": "<è»Šç¨®ã®ç¿»è¨³çµæœ>"
}
"""

def translate_with_llm(brand, model):
    """LLMã«å•ã„åˆã‚ã›ã¦ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»è»Šç¨®ã‚’ç¿»è¨³"""
    prompt = f"{PROMPT_TEMPLATE}\n\nå¯¾è±¡:\nãƒ–ãƒ©ãƒ³ãƒ‰: {brand}\nè»Šç¨®: {model}\n"
    try:
        res = client.chat.completions.create(
            model=MODEL,
            messages=[{"role": "system", "content": "You are an automotive naming expert."},
                      {"role": "user", "content": prompt}],
            temperature=0.2,
        )
        text = res.choices[0].message.content.strip()
        if "{" in text:
            data = json.loads(text[text.index("{"): text.rindex("}") + 1])
            return data.get("brand_ja", ""), data.get("model_ja", "")
        else:
            return "", text
    except Exception as e:
        print("âš ï¸ ç¿»è¨³ã‚¨ãƒ©ãƒ¼:", e)
        return "", ""

def main():
    rows_out = []
    with open(INPUT_CSV, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for i, row in enumerate(reader, 1):
            brand, model = row["brand"], row["model"]
            print(f"[{i}] ç¿»è¨³ä¸­: {brand} / {model}")
            brand_ja, model_ja = translate_with_llm(brand, model)
            row["brand_ja"] = brand_ja
            row["model_ja"] = model_ja
            rows_out.append(row)
            time.sleep(SLEEP_SEC)

    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)
    with open(OUTPUT_CSV, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=rows_out[0].keys())
        writer.writeheader()
        writer.writerows(rows_out)
    print("âœ… å‡ºåŠ›å®Œäº†:", OUTPUT_CSV)

if __name__ == "__main__":
    main()
