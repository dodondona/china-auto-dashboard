#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
append_series_url_and_enrich_title_llm.py
-----------------------------------------------------
- autohome.com.cn/rank/1 ã‚’ Playwright ã§é–‹ã
- ãƒ©ãƒ³ã‚­ãƒ³ã‚°å„è¡Œã‚’ DOM ã‹ã‚‰åˆ—æŒ™ã—ã€button[data-series-id] ã‹ã‚‰ series_url ã‚’ç”Ÿæˆ
- rank ã¯ data-rank-num ãŒã‚ã‚Œã°ãã‚Œã‚’ã€ç„¡ã‘ã‚Œã°ã€Œè¡Œã®è¦‹ãŸç›®ã®é †ä½ã€ã‚„å‡ºç¾é †ã§è£œå®Œ
- å„ series_url ã‚’é–‹ã <title> ã‚’å–å¾—
- title ã‚’ LLM ã§è§£æã—ã¦ brand/model ã‚’æ¨å®š
- rank / series_url / count / title / brand / model ã‚’ CSV ã¸

ä¾å­˜:
  pip install playwright openai pandas
  playwright install chromium
"""

import os
import re
import json
import argparse
from pathlib import Path

import pandas as pd
from playwright.sync_api import sync_playwright, TimeoutError as PWTimeout
from openai import OpenAI

UA_MOBILE = (
    "Mozilla/5.0 (Linux; Android 11; Pixel 5) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/122.0.0.0 Mobile Safari/537.36"
)

PROMPT_BRAND_MODEL = (
    "ä½ å°†çœ‹åˆ°ä¸€ä¸ªæ±½è½¦è½¦ç³»é¡µé¢çš„æ ‡é¢˜ï¼Œè¯·ä»æ ‡é¢˜ä¸­è§£æå‡ºã€å“ç‰Œåã€‘å’Œã€è½¦ç³»åã€‘ã€‚\n"
    "ä¸¥æ ¼ä»¥ JSON è¾“å‡ºï¼š{\"brand\":\"å“ç‰Œå\",\"model\":\"è½¦ç³»å\"}\n"
    "è‹¥æ— æ³•åˆ¤æ–­ï¼Œç•™ç©ºå­—ç¬¦ä¸²ã€‚"
)

def goto_with_retries(page, url: str, timeout_ms: int = 120000):
    """www ã¨ m ã‚’é †ã«è©¦ã™ã€‚"""
    candidates = [url]
    if "www.autohome.com.cn" in url:
        candidates.append(url.replace("www.autohome.com.cn", "m.autohome.com.cn"))
    last_err = None
    for u in candidates:
        try:
            page.goto(u, wait_until="load", timeout=timeout_ms)
            return u
        except Exception as e:
            last_err = e
            page.wait_for_timeout(1000)
    raise last_err or RuntimeError("Failed to open page")

def wait_rank_dom_ready(page, timeout_ms=120000):
    """
    ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®è¡ŒãŒç¾ã‚Œã‚‹ã¾ã§å¾…ã¤ã€‚
    data-rank-num ãŒç„¡ã„æ§‹æˆã‚‚ã‚ã‚‹ã®ã§ã€è¤‡æ•°ã‚»ãƒ¬ã‚¯ã‚¿ã§å¾…æ©Ÿã€‚
    """
    try:
        page.wait_for_selector("div.rank-num, em.rank, [data-rank-num], button[data-series-id]",
                               timeout=timeout_ms, state="visible")
    except PWTimeout as e:
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã«HTMLã‚’ä¿å­˜
        Path("data").mkdir(parents=True, exist_ok=True)
        with open("data/debug_rankpage_error.html", "w", encoding="utf-8") as f:
            f.write(page.content())
        raise e

def scroll_to_bottom(page, idle_ms=700, max_rounds=50):
    """ç„¡é™ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã®æœ«å°¾ã¾ã§èª­ã‚€ã€‚"""
    prev = -1
    stable = 0
    for _ in range(max_rounds):
        page.mouse.wheel(0, 24000)
        page.wait_for_timeout(idle_ms)
        n = page.evaluate("() => document.querySelectorAll('button[data-series-id]').length")
        if n == prev:
            stable += 1
        else:
            stable = 0
        prev = n
        if stable >= 3:
            break
    return prev

def safe_int(x):
    try:
        return int(str(x).strip())
    except Exception:
        return None

def nearest_row_container(el):
    """è¡Œã‚³ãƒ³ãƒ†ãƒŠã£ã½ã„ä¸Šä½è¦ç´ ã‚’è¿”ã™ï¼ˆã‚»ãƒ¬ã‚¯ã‚¿æºã‚Œå¯¾ç­–ï¼‰ã€‚"""
    c = el
    for _ in range(6):
        if c is None:
            break
        # è¡Œå†…ã«è¦‹ãˆã‚‹å…¸å‹çš„è¦ç´ ãŒã‚ã‚Œã°ã“ã“ã‚’è¡Œã¨ã¿ãªã™
        if c.query_selector("button[data-series-id]") and (
            c.get_attribute("data-rank-num") or
            c.query_selector("div.rank-num, em.rank") or
            c.query_selector(".tw-text-lg.tw-font-medium")
        ):
            return c
        c = c.evaluate_handle("n => n.parentElement").as_element()
    return el

def parse_rank_from_container(container):
    """data-rank-num > å¯è¦–ã®é †ä½ > None ã®é †ã«å–å¾—ã€‚"""
    attr = container.get_attribute("data-rank-num")
    rk = safe_int(attr)
    if rk is not None:
        return rk
    badge = container.query_selector("div.rank-num, em.rank")
    if badge:
        txt = (badge.inner_text() or "").strip()
        rk = safe_int(re.sub(r"[^\d]", "", txt))
        if rk is not None:
            return rk
    return None

def parse_count_from_container(container):
    txt = (container.inner_text() or "").strip()
    m = re.search(r"(\d{4,6})\s*è½¦ç³»é”€é‡", txt)
    return safe_int(m.group(1)) if m else None

def extract_rank_and_links(page):
    """
    è¡Œã‚’åˆ—æŒ™ã—ã€rank / series_url / count ã‚’æŠ½å‡ºã€‚
    - ãƒ©ã‚¤ãƒ³ã®åŸºæº–ã¯ button[data-series-id]
    - rankã¯ data-rank-num â†’ è¡¨ç¤ºé †ä½ â†’ å‡ºç¾é †
    """
    buttons = page.query_selector_all("button[data-series-id]") or []
    rows = []
    for idx, btn in enumerate(buttons, start=1):
        sid = btn.get_attribute("data-series-id")
        series_url = f"https://www.autohome.com.cn/{sid}/" if sid else None
        cont = nearest_row_container(btn)
        rk = parse_rank_from_container(cont)
        if rk is None:
            rk = idx
        count = parse_count_from_container(cont)
        rows.append({"rank": rk, "series_url": series_url, "count": count})
    return rows

def get_title_from_series_url(page, url):
    """å€‹åˆ¥è»Šç³»ãƒšãƒ¼ã‚¸ã®<title>ã‚’å–å¾—ã€‚å¤±æ•—æ™‚ã¯ç©ºæ–‡å­—ã€‚"""
    if not url:
        return ""
    try:
        page.goto(url, wait_until="domcontentloaded", timeout=25000)
        page.wait_for_timeout(400)
        return (page.title() or "").strip()
    except Exception:
        return ""

def llm_parse_brand_model(client, model_name, title):
    """LLMã«ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¸¡ã—ã¦ brand/model ã‚’æŠ½å‡ºã€‚"""
    if not title:
        return {"brand": "", "model": ""}
    try:
        resp = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": PROMPT_BRAND_MODEL},
                {"role": "user", "content": title},
            ],
            temperature=0,
            max_tokens=200,
        )
        out = (resp.choices[0].message.content or "").strip()
        m = re.search(r"\{.*\}", out, re.S)
        data = json.loads(m.group(0)) if m else {}
        return {
            "brand": (data.get("brand") or "").strip(),
            "model": (data.get("model") or "").strip(),
        }
    except Exception:
        return {"brand": "", "model": ""}

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--rank-url", default="https://www.autohome.com.cn/rank/1")
    ap.add_argument("--output", required=True)
    ap.add_argument("--model", default="gpt-4o-mini")
    ap.add_argument("--max-series", type=int, default=60)
    args = ap.parse_args()

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    out = Path(args.output)
    out.parent.mkdir(parents=True, exist_ok=True)

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, args=["--disable-blink-features=AutomationControlled"])
        ctx = browser.new_context(
            user_agent=UA_MOBILE,
            viewport={"width": 480, "height": 960},
            locale="zh-CN",
            timezone_id="Asia/Shanghai",
        )
        page = ctx.new_page()

        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒšãƒ¼ã‚¸
        print(f"ğŸŒ Loading {args.rank_url}")
        goto_with_retries(page, args.rank_url, timeout_ms=120000)
        wait_rank_dom_ready(page, timeout_ms=120000)
        total = scroll_to_bottom(page)
        print(f"ğŸ§© detected buttons(data-series-id): {total}")

        base_rows = extract_rank_and_links(page)
        if not base_rows:
            # ãƒ‡ãƒãƒƒã‚°ãƒ€ãƒ³ãƒ—
            Path("data").mkdir(parents=True, exist_ok=True)
            with open("data/debug_rankpage_empty.html", "w", encoding="utf-8") as f:
                f.write(page.content())
            # ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•ï¼ˆç©ºã§ã‚‚rankã ã‘æ¡ç•ªï¼‰
            items = page.query_selector_all("[data-rank-num]") or []
            base_rows = [{"rank": i, "series_url": None, "count": None} for i, _ in enumerate(items, start=1)]

        # å„ series_url ã® <title> å–å¾—
        print("ğŸ” Fetching <title> from series_url ...")
        subset = sorted(base_rows, key=lambda r: r["rank"])[: args.max_series]
        for r in subset:
            r["title"] = get_title_from_series_url(page, r.get("series_url"))
            page.wait_for_timeout(250)

        browser.close()

    # LLM ã§ brand/model ã‚’è§£æ
    print("ğŸ¤– Parsing brand/model via LLM...")
    for r in subset:
        r.update(llm_parse_brand_model(client, args.model, r.get("title", "")))

    # rankåˆ—ã®ä¿è¨¼ã¨å®‰å®šã‚½ãƒ¼ãƒˆ
    rows_fixed = []
    for i, r in enumerate(subset, start=1):
        rk = safe_int(r.get("rank")) or i
        rows_fixed.append({**r, "rank": rk})
    df = pd.DataFrame(rows_fixed)
    if "rank" not in df.columns or df["rank"].isna().all():
        df["rank"] = range(1, len(df) + 1)
    df = df.sort_values("rank").reset_index(drop=True)

    df.to_csv(out, index=False, encoding="utf-8-sig")
    print(f"âœ… Saved: {out}  (rows={len(df)})")

if __name__ == "__main__":
    main()
