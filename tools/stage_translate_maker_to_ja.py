# -*- coding: utf-8 -*-
# tools/stage_translate_maker_to_ja.py
#
# ç›®çš„:
#   - 'manufacturer'åˆ—ã‚’æ—¥æœ¬èªåŒ–ã—ã¦'manufacturer_ja'åˆ—ã‚’è¿½åŠ 
#   - 'name'åˆ—ã®éš£ã«'global_name'åˆ—ã‚’è¿½åŠ 
#   - global_nameã¯è¾æ›¸å„ªå…ˆã€ãªã‘ã‚Œã°ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€æœ€å¾Œã«LLMç¿»è¨³
#   - æ—¢å­˜å‹•ä½œãƒ»å‡ºåŠ›æ§‹é€ ã¯å¤‰æ›´ã—ãªã„
#
# ä½¿ã„æ–¹:
#   python tools/stage_translate_maker_to_ja.py <csv>

import os, sys, re, json, time
from pathlib import Path
import pandas as pd
from openai import OpenAI

try:
    sys.stdout.reconfigure(line_buffering=True)
except Exception:
    pass

# ==== ãƒ¡ãƒ¼ã‚«ãƒ¼ç¿»è¨³è¾æ›¸ ====
DICT_ZH_TO_JA = {
    # âœ… è‡ªä¸»ãƒ–ãƒ©ãƒ³ãƒ‰
    "æ¯”äºšè¿ª": "BYD",
    "å‰åˆ©": "å‰åˆ©ï¼ˆGeelyï¼‰",
    "å‰åˆ©é“¶æ²³": "å‰åˆ©éŠ€æ²³ï¼ˆGeely Galaxyï¼‰",
    "å¥‡ç‘": "å¥‡ç‘ï¼ˆCheryï¼‰",
    "å¥‡ç‘é£äº‘": "å¥‡ç‘é¢¨é›²ï¼ˆChery Fengyunï¼‰",
    "é•¿å®‰": "é•·å®‰ï¼ˆChanganï¼‰",
    "é•¿å®‰å¯æº": "é•·å®‰å•“æºï¼ˆChangan Qiyuanï¼‰",
    "å“ˆå¼—": "å“ˆå¼—ï¼ˆHavalï¼‰",
    "é­ç‰Œ": "é­ç‰Œï¼ˆWEYï¼‰",
    "çº¢æ——": "ç´…æ——ï¼ˆHongqiï¼‰",
    "åçˆµ": "åçˆµï¼ˆMGï¼‰",
    "è£å¨": "æ „å¨ï¼ˆRoeweï¼‰",
    "é›¶è·‘æ±½è½¦": "é›¶è·‘ï¼ˆLeapmotorï¼‰",
    "ç†æƒ³æ±½è½¦": "ç†æƒ³ï¼ˆLi Autoï¼‰",
    "å°é¹": "å°éµ¬ï¼ˆXpengï¼‰",
    "æç‹": "æ¥µç‹ï¼ˆARCFOXï¼‰",
    "æ·±è“æ±½è½¦": "æ·±è—ï¼ˆDeepalï¼‰",
    "é¢†å…‹": "ãƒªãƒ³ã‚¯ãƒ»ã‚¢ãƒ³ãƒ‰ãƒ»ã‚³ãƒ¼ï¼ˆLynk & Coï¼‰",
    "ä¹é“": "æ¥½é“ï¼ˆLe Daoï¼‰",
    "æ–¹ç¨‹è±¹": "æ–¹ç¨‹è±¹ï¼ˆFang Cheng Baoï¼‰",
    "iCAR": "iCARï¼ˆå¥‡ç‘iCARï¼‰",
    "è…¾åŠ¿": "é¨°å‹¢ï¼ˆDENZAï¼‰",
    "ARCFOX": "æ¥µç‹ï¼ˆARCFOXï¼‰",

    # âœ… ä¸Šæ±½ã‚°ãƒ«ãƒ¼ãƒ—ç³»
    "ä¸Šæ±½": "ä¸Šæµ·æ±½è»Šï¼ˆSAICï¼‰",
    "ä¸Šæ±½é›†å›¢": "ä¸Šæµ·æ±½è»Šï¼ˆSAICï¼‰",
    "ä¸Šæ±½é€šç”¨": "ä¸Šæ±½é€šç”¨ï¼ˆSAIC-GMï¼‰",
    "ä¸Šæ±½é€šç”¨äº”è±": "ä¸Šæ±½é€šç”¨äº”è±ï¼ˆSGMWï¼äº”è±ï¼‰",
    "äº”è±æ±½è½¦": "äº”è±ï¼ˆWulingï¼‰",
    "å®éª": "å®é§¿ï¼ˆBaojunï¼‰",

    # âœ… å¤–è³‡ç³»åˆå¼
    "å¤§ä¼—": "ãƒ•ã‚©ãƒ«ã‚¯ã‚¹ãƒ¯ãƒ¼ã‚²ãƒ³ï¼ˆVolkswagenï¼‰",
    "å¥¥è¿ª": "ã‚¢ã‚¦ãƒ‡ã‚£ï¼ˆAudiï¼‰",
    "å®é©¬": "BMW",
    "å¥”é©°": "ãƒ¡ãƒ«ã‚»ãƒ‡ã‚¹ãƒ»ãƒ™ãƒ³ãƒ„ï¼ˆMercedes-Benzï¼‰",
    "ä¸°ç”°": "ãƒˆãƒ¨ã‚¿ï¼ˆToyotaï¼‰",
    "æœ¬ç”°": "ãƒ›ãƒ³ãƒ€ï¼ˆHondaï¼‰",
    "æ—¥äº§": "æ—¥ç”£ï¼ˆNissanï¼‰",
    "é©¬è‡ªè¾¾": "ãƒãƒ„ãƒ€ï¼ˆMazdaï¼‰",
    "ä¸‰è±": "ä¸‰è±ï¼ˆMitsubishiï¼‰",
    "é“ƒæœ¨": "ã‚¹ã‚ºã‚­ï¼ˆSuzukiï¼‰",
    "æ–¯å·´é²": "ã‚¹ãƒãƒ«ï¼ˆSubaruï¼‰",
    "é›·å…‹è¨æ–¯": "ãƒ¬ã‚¯ã‚µã‚¹ï¼ˆLexusï¼‰",
    "åˆ«å…‹": "ãƒ“ãƒ¥ã‚¤ãƒƒã‚¯ï¼ˆBuickï¼‰",
    "é›ªä½›å…°": "ã‚·ãƒœãƒ¬ãƒ¼ï¼ˆChevroletï¼‰",
    "æ·é€”": "æ·é€”ï¼ˆJetourï¼‰",
    "å¥”è…¾": "å¥”é¨°ï¼ˆBestuneï¼‰",
    "æ²ƒå°”æ²ƒ": "ãƒœãƒ«ãƒœï¼ˆVolvoï¼‰",
    "æ·è¾¾": "ã‚¸ã‚§ãƒƒã‚¿ï¼ˆJettaï¼‰",
    "å‡¯è¿ªæ‹‰å…‹": "ã‚­ãƒ£ãƒ‡ãƒ©ãƒƒã‚¯ï¼ˆCadillacï¼‰",
    "ç¦ç‰¹": "ãƒ•ã‚©ãƒ¼ãƒ‰ï¼ˆFordï¼‰",
    "ç°ä»£": "ãƒ’ãƒ¥ãƒ³ãƒ€ã‚¤ï¼ˆHyundaiï¼‰",
    "smart": "ã‚¹ãƒãƒ¼ãƒˆï¼ˆsmartï¼‰",
    "èµ·äºš": "ã‚­ã‚¢ï¼ˆKiaï¼‰",
    "æ—è‚¯": "ãƒªãƒ³ã‚«ãƒ¼ãƒ³ï¼ˆLincolnï¼‰",
    "é›ªé“é¾™": "ã‚·ãƒˆãƒ­ã‚¨ãƒ³ï¼ˆCitroÃ«nï¼‰",
    "æ·è±¹": "ã‚¸ãƒ£ã‚¬ãƒ¼ï¼ˆJaguarï¼‰",

    # âœ… æ–°èˆˆãŠã‚ˆã³å¤–è³‡ç‹¬è³‡
    "ç‰¹æ–¯æ‹‰": "ãƒ†ã‚¹ãƒ©ï¼ˆTeslaï¼‰",
    "å°ç±³æ±½è½¦": "å°ç±³ï¼ˆXiaomi Autoï¼‰",
    "AITO é—®ç•Œ": "AITOï¼ˆå•ç•Œï¼‰",
    "ARCFOXæç‹": "æ¥µç‹ï¼ˆARCFOXï¼‰",
    "æ–¹ç¨‹è±¹æ±½è½¦": "æ–¹ç¨‹è±¹ï¼ˆFang Cheng Baoï¼‰",
    "å“ˆå¼—çŒ›é¾™æ–°èƒ½æº": "å“ˆå¼—ï¼ˆHavalï¼‰",
    "æ·±è“": "æ·±è—ï¼ˆDeepalï¼‰",
    "é“¶æ²³": "éŠ€æ²³ï¼ˆGeely Galaxyï¼‰",
    "å¯æº": "å•“æºï¼ˆChangan Qiyuanï¼‰",
}

# ==== OpenAI Translator ====
class Translator:
    def __init__(self, model: str, api_key: str | None):
        self.model = model
        self.client = OpenAI(api_key=api_key) if api_key else None
        self.batch_size = 60
        self.retries = 3
        self.sleep_base = 1.2

    def translate_unique(self, terms: list[str]) -> dict[str, str]:
        if not self.client:
            print("âš ï¸ No OpenAI API key; skipping LLM translation")
            return {t: t for t in terms}
        
        result = {}
        for i in range(0, len(terms), self.batch_size):
            batch = terms[i:i + self.batch_size]
            for attempt in range(self.retries):
                try:
                    prompt = self._build_prompt(batch)
                    resp = self.client.chat.completions.create(
                        model=self.model,
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.3,
                    )
                    content = resp.choices[0].message.content or ""
                    parsed = self._parse_response(content, batch)
                    result.update(parsed)
                    break
                except Exception as e:
                    print(f"âš ï¸ LLM translation attempt {attempt+1}/{self.retries} failed: {e}")
                    if attempt < self.retries - 1:
                        time.sleep(self.sleep_base ** (attempt + 1))
                    else:
                        for t in batch:
                            result[t] = t
        return result

    def _build_prompt(self, terms: list[str]) -> str:
        lines = "\n".join(f"{i+1}. {t}" for i, t in enumerate(terms))
        return f"""ä»¥ä¸‹ã®ä¸­å›½èªã®è‡ªå‹•è»Šãƒ¡ãƒ¼ã‚«ãƒ¼åã¾ãŸã¯è»Šåã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
å¯èƒ½ã§ã‚ã‚Œã°æ—¥æœ¬èªåã¨è‹±èªè¡¨è¨˜ã‚’ä½µè¨˜ã—ã¦ãã ã•ã„ï¼ˆä¾‹: ãƒˆãƒ¨ã‚¿ï¼ˆToyotaï¼‰ï¼‰ã€‚
å…ƒã®ä¸­å›½èªãŒæ—¢ã«è‹±èªã‚„ãƒ­ãƒ¼ãƒå­—ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã—ã¦ãã ã•ã„ã€‚

å…¥åŠ›:
{lines}

å‡ºåŠ›å½¢å¼ï¼ˆç•ªå·: ç¿»è¨³çµæœï¼‰:
1. ç¿»è¨³çµæœ1
2. ç¿»è¨³çµæœ2
..."""

    def _parse_response(self, content: str, batch: list[str]) -> dict[str, str]:
        result = {}
        lines = [ln.strip() for ln in content.split("\n") if ln.strip()]
        for i, line in enumerate(lines):
            m = re.match(r"^\d+[\.\)]\s*(.+)$", line)
            if m and i < len(batch):
                result[batch[i]] = m.group(1).strip()
        # Fill missing translations
        for t in batch:
            if t not in result:
                result[t] = t
        return result

# ==== è¾æ›¸ã®è‡ªå‹•æ›´æ–° ====
def update_dictionary_file(dict_name: str, new_entries: dict[str, str]):
    """
    è¾æ›¸ã«æ–°ã—ã„ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ ã—ã¦Pythonãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãæˆ»ã™
    """
    if not new_entries:
        return
    
    script_path = Path(__file__)
    
    try:
        with script_path.open("r", encoding="utf-8") as f:
            content = f.read()
        
        # è¾æ›¸ã®é–‹å§‹ãƒ»çµ‚äº†ä½ç½®ã‚’æ¤œç´¢
        if dict_name == "DICT_ZH_TO_JA":
            pattern = r"(DICT_ZH_TO_JA = \{[^}]*?)(\})"
        elif dict_name == "DICT_GLOBAL_NAME":
            pattern = r"(DICT_GLOBAL_NAME = \{[^}]*?)(\}\n\})"  # ãƒã‚¹ãƒˆã—ãŸæ§‹é€ 
        else:
            return
        
        match = re.search(pattern, content, re.DOTALL)
        if not match:
            print(f"âš ï¸ Could not find {dict_name} in script")
            return
        
        # æ–°ã—ã„ã‚¨ãƒ³ãƒˆãƒªã‚’ç”Ÿæˆ
        new_lines = []
        for key, value in sorted(new_entries.items()):
            # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
            key_escaped = key.replace('"', '\\"')
            value_escaped = value.replace('"', '\\"')
            new_lines.append(f'    "{key_escaped}": "{value_escaped}",')
        
        # è¾æ›¸ã«è¿½åŠ 
        dict_start = match.group(1)
        dict_end = match.group(2)
        
        # æ—¢å­˜ã®æœ€å¾Œã®ã‚«ãƒ³ãƒã‚’ç¢ºèª
        if not dict_start.rstrip().endswith(","):
            dict_start += ","
        
        new_dict = dict_start + "\n    # LLMã§è‡ªå‹•è¿½åŠ \n" + "\n".join(new_lines) + "\n" + dict_end
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        new_content = content[:match.start()] + new_dict + content[match.end():]
        
        with script_path.open("w", encoding="utf-8") as f:
            f.write(new_content)
        
        print(f"âœ… Added {len(new_entries)} entries to {dict_name}")
        
    except Exception as e:
        print(f"âš ï¸ Failed to update dictionary: {e}")

def translate_with_dict_update(kind: str, terms: list[str], fixed_map: dict[str, str], tr: Translator) -> dict[str, str]:
    """
    å›ºå®šè¾æ›¸ã§ç¿»è¨³ â†’ ãªã‘ã‚Œã°LLM â†’ è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ 
    """
    out: dict[str, str] = {}

    # 1) å›ºå®šè¾æ›¸
    for t in terms:
        if t in fixed_map:
            out[t] = fixed_map[t]

    # 2) LLM
    need = [t for t in terms if t not in out]
    if need:
        print(f"ğŸ¤– Translating {len(need)} {kind}(s) with LLM...")
        llm_map = tr.translate_unique(need)
        out.update(llm_map)
        
        # 3) è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ 
        dict_name = "DICT_ZH_TO_JA" if kind == "manufacturer" else "DICT_GLOBAL_NAME"
        update_dictionary_file(dict_name, llm_map)

    return out

DICT_KEYS_SORTED = sorted(DICT_ZH_TO_JA.keys(), key=len, reverse=True)

# ==== ã‚°ãƒ­ãƒ¼ãƒãƒ«åè¾æ›¸ ====
DICT_GLOBAL_NAME = {
    # å‰10ä½
    "å®å…‰MINIEV": "å®å…‰MINIEV",
    "Model Y": "ãƒ¢ãƒ‡ãƒ«Y",
    "æ˜Ÿæ„¿": "æ˜Ÿé¡˜",
    "ç§¦PLUS": "ç§¦PLUS",
    "è½©é€¸": "ã‚·ãƒ«ãƒ•ã‚£",
    "æµ·ç‹®06æ–°èƒ½æº": "Sealion 06",
    "åšè¶ŠL": "åšè¶ŠL",
    "æµ·è±¹06æ–°èƒ½æº": "Seal 06",
    "ç§¦L": "ç§¦L",
    "å…ƒUP": "Atto2",

    # 11â€“20
    "æµ·é¸¥": "ã‚·ãƒ¼ã‚¬ãƒ«",
    "é€Ÿè…¾": "ã‚µã‚®ã‚¿ãƒ¼ï¼ˆSagitarï¼‰",
    "é•¿å®‰Lumin": "ãƒ«ãƒŸãƒ³ï¼ˆLuminï¼‰",
    "å°ç±³YU7": "YU7",
    "æœ—é€¸": "ãƒ©ãƒ´ã‚£ãƒ¼ãƒ€",
    "æµ·è±š": "ãƒ‰ãƒ«ãƒ•ã‚£ãƒ³ï¼ˆDolphinï¼‰",
    "é—®ç•ŒM8": "AITO M8",
    "å‡¯ç¾ç‘": "ã‚«ãƒ ãƒª",
    "Model 3": "ãƒ¢ãƒ‡ãƒ«3",
    "RAV4è£æ”¾": "RAV4",

    # 21â€“40
    "å°ç±³SU7": "SU7",
    "é€”è§‚L": "ãƒ†ã‚£ã‚°ã‚¢ãƒ³L",
    "å¸•è¨ç‰¹": "ãƒ‘ã‚µãƒ¼ãƒˆ",
    "é€¸åŠ¨": "Eado",
    "æ˜Ÿè¶ŠL": "Monjaro",
    "è¿ˆè…¾": "ãƒã‚´ã‚¿ãƒ³",
    "å“ˆå¼—å¤§ç‹—": "ãƒ“ãƒƒã‚°ãƒ‰ãƒƒã‚°",
    "å¥¥è¿ªA6L": "A6L",
    "æ¢å²³": "ã‚¿ã‚¤ãƒ­ãƒ³ï¼ˆTayronï¼‰",
    "å¡ç½—æ‹‰é”æ”¾": "ã‚«ãƒ­ãƒ¼ãƒ©ã‚¯ãƒ­ã‚¹",

    # 41â€“60
    "ç‘è™8": "ãƒ†ã‚£ã‚´8ï¼ˆTiggo 8ï¼‰",
    "å°é¹MONA M03": "MONA M03",
    "æœ¬ç”°CR-V": "CR-V",
    "çº¢æ——H5": "H5",
    "ç¼¤è¶Š": "ã‚¯ãƒ¼ãƒ«ãƒ¬ã‚¤ï¼ˆCoolrayï¼‰",
    "é”‹å…°è¾¾": "ãƒ•ãƒ­ãƒ³ãƒˆãƒ©ãƒ³ãƒ€ãƒ¼",
    "è‰¾ç‘æ³½8": "ã‚¢ãƒªã‚¾8ï¼ˆArrizo 8ï¼‰",
    "å®‹Proæ–°èƒ½æº": "Sealion 5 DMâ€‘i",
    "é›…é˜": "ã‚¢ã‚³ãƒ¼ãƒ‰",
    "æ·±è“S05": "Deepal S05",
    "å¥”é©°Eçº§": "Eã‚¯ãƒ©ã‚¹",
    "ç†ŠçŒ«": "ãƒ‘ãƒ³ãƒ€",
    "é“¶æ²³A7": "éŠ€æ²³A7",
    "æ˜‚ç§‘å¨Plus": "ã‚¨ãƒ³ãƒ“ã‚¸ãƒ§ãƒ³Plusï¼ˆEnvision Plusï¼‰",
    "é›¶è·‘C10": "C10",
    "å…ƒPLUS": "Atto 3",
    "æµ·è±¹05 DM-i": "Seal 05 DM-i",
    "é›¶è·‘B01": "B01",
    "å®é©¬3ç³»": "3ã‚·ãƒªãƒ¼ã‚º",
    "é€”å²³": "é€”å²³ï¼ˆTharuï¼‰",

    # 61â€“80
    "å¥”è…¾å°é©¬": "ãƒãƒ‹ãƒ¼ï¼ˆPonyï¼‰",
    "ç†æƒ³L6": "L6",
    "å¥¥è¿ªQ5L": "Q5L",
    "å¨å…°è¾¾": "ã‚¦ã‚£ãƒ©ãƒ³ãƒ€ãƒ¼",
    "æµ·ç‹®05 EV": "æµ·ç‹®05 EV",
    "é•¿å®‰CS75PLUS": "CS75ãƒ—ãƒ©ã‚¹",
    "MG4": "MG4",
    "äºšæ´²é¾™": "ã‚¢ãƒãƒ­ãƒ³",
    "å¥”é©°GLC": "GLC",
    "å“ˆå¼—çŒ›é¾™æ–°èƒ½æº": "ãƒ©ãƒ—ã‚¿ãƒ¼ï¼ˆHaval Raptorï¼‰",
    "å®‹PLUSæ–°èƒ½æº": "å®‹PLUSæ–°èƒ½æºï¼ˆSong PLUS EVï¼‰",
    "ä¹é“L90": "ä¹é“L90",
    "é›¶è·‘C11": "C11",
    "é—®ç•ŒM9": "å•ç•ŒM9ï¼ˆAITO M9ï¼‰",
    "å¥”é©°Cçº§": "Cã‚¯ãƒ©ã‚¹",
    "é•¿å®‰å¯æºQ07": "å•“æºQ07ï¼ˆQiyuan Q07ï¼‰",
    "æ·é€”X70": "X70ï¼ˆJetour X70ï¼‰",
    "é“¶æ²³E5": "éŠ€æ²³E5",
    "å®‹L DM-i": "å®‹L DM-i",
    "æç‹T1": "æ¥µç‹T1ï¼ˆARCFOX T1ï¼‰",

    # 81â€“100
    "é“¶æ²³æ˜Ÿè€€8": "éŠ€æ²³æ˜Ÿè€€8",
    "é£äº‘A9L": "é¢¨é›²A9L",
    "çš“å½±": "ãƒ–ãƒªãƒ¼ã‚º",
    "äº”è±ç¼¤æœ": "ãƒ“ãƒ³ã‚´ï¼ˆBingoï¼‰",
    "é›¶è·‘B10": "B10",
    "é•¿å®‰X5 PLUS": "X5ãƒ—ãƒ©ã‚¹",
    "é›¶è·‘C16": "C16",
    "å®é©¬5ç³»": "5ã‚·ãƒªãƒ¼ã‚º",
    "é“‚æ™º3X": "bZ3X",
    "è£å¨i5": "i5",
    "é“¶æ²³æ˜Ÿèˆ°7": "éŠ€æ²³æ˜Ÿè‰¦7",
    "èµ›é‚£SIENNA": "ã‚·ã‚¨ãƒŠ",
    "é’›7": "ãƒ¬ãƒ‘ãƒ¼ãƒ‰7ï¼ˆLeopard 7ï¼‰",
    "å°é¹P7": "P7",
    "å®é©¬X3": "X3",
    "é•¿å®‰UNI-Zæ–°èƒ½æº": "UNI-Z",
    "é­ç‰Œ é«˜å±±": "é«˜å±±ï¼ˆWey Gaoshanï¼‰",
    "iCAR è¶…çº§V23": "iCAR V23",
    "å¥¥è¿ªA4L": "A4L",
    "çº¢æ——HS5": "HS5",
    "é€å®¢": "ã‚­ãƒ£ã‚·ãƒ¥ã‚«ã‚¤",
    "é¢†å…‹900": "Lynk & Co 09",
    "æ˜Ÿç‘": "Preface",
    "è…¾åŠ¿D9": "Denza D9",
    "é©±é€èˆ°05": "Destroyer 05",
    "å¡ç½—æ‹‰": "ã‚«ãƒ­ãƒ¼ãƒ©",
    "åˆ«å…‹GL8æ–°èƒ½æº": "GL8",
    "å®æ¥": "Bora",
    "ä¼ ç¥ºGS3": "GS3",

    # è¿½åŠ ç²¾æŸ»åˆ†
    "ID.4 CROZZ": "ID.4 CROZZ",
    "ID.4 X": "ID.4 X",
    "T-ROCæ¢æ­Œ": "T-ROCï¼ˆæ¢æ­Œï¼‰",
    "ä¸€æ±½-å¤§ä¼—CC": "CC",
    "ä¼Šå…°ç‰¹": "ã‚¨ãƒ©ãƒ³ãƒˆãƒ©ï¼ˆElantraï¼‰",
    "å‡Œæ¸¡": "ãƒ©ãƒ¢ãƒ³ãƒ‰ï¼ˆLamandoï¼‰",
    "å‡¯è¿ªæ‹‰å…‹CT5": "CT5",
    "å‡¯è¿ªæ‹‰å…‹XT4": "XT4",
    "å‡¯è¿ªæ‹‰å…‹XT5": "XT5",
    "åˆ«å…‹E5": "E5",
    "åˆ«å…‹GL8": "GL8",
    "è’™è¿ªæ¬§": "ãƒ¢ãƒ³ãƒ‡ã‚ªï¼ˆMondeoï¼‰",
    "æ²ƒå°”æ²ƒS90": "S90",
    "æ²ƒå°”æ²ƒXC60": "XC60",
    "ç¦ç‘è¿ª": "ãƒ•ã‚©ãƒ«ãƒ†ï¼ˆForteï¼‰",
    "èµ›å›¾æ–¯": "ã‚»ãƒ«ãƒˆã‚¹ï¼ˆSeltosï¼‰",
    "smartç²¾çµ#1": "smartç²¾çµ#1",
    "èˆªæµ·å®¶": "ãƒãƒ¼ãƒãƒ©ã‚¹ï¼ˆNautilusï¼‰",
    "é”ç•Œ": "ã‚¨ãƒƒã‚¸ï¼ˆEdgeï¼‰",
    "é©¬è‡ªè¾¾CX-5": "CX-5",
    "é©¬è‡ªè¾¾EZ-60": "EZ-60",
    "çš‡å† é™†æ”¾": "ã‚¯ãƒ©ã‚¦ãƒ³ã‚¯ãƒ«ãƒ¼ã‚¬ãƒ¼ï¼ˆCrown Klugerï¼‰",
    "é›·å‡Œ": "ãƒ¬ãƒ“ãƒ³ï¼ˆLevinï¼‰",
    "é«˜å°”å¤«": "ã‚´ãƒ«ãƒ•ï¼ˆGolfï¼‰",
}

# ==== ãƒ”ãƒ³ã‚¤ãƒ³è£œåŠ© ====
try:
    from pypinyin import lazy_pinyin
    _PINYIN_OK = True
except Exception:
    _PINYIN_OK = False

_HAN = r"\u4e00-\u9fff"

def add_block_pinyin_inline(name: str, global_name: str) -> str:
    if re.search(r"[A-Za-zï½-ï½šï¼¡-ï¼ºã‚¡-ãƒ´ãƒ¼]", global_name or ""):
        return global_name
    if global_name or not re.search(fr"[{_HAN}]", name or ""):
        return global_name or name
    if not _PINYIN_OK:
        return name
    s = str(name)
    out = []
    i = 0
    while i < len(s):
        if re.match(fr"[{_HAN}]", s[i]):
            j = i
            while j < len(s) and re.match(fr"[{_HAN}]", s[j]):
                j += 1
            block = s[i:j]
            py = " ".join(lazy_pinyin(block))
            out.append(f"{block}({py})")
            i = j
        else:
            out.append(s[i])
            i += 1
    return "".join(out)

# ==== ãƒ¡ã‚¤ãƒ³ ====
def process_csv(csv_path: Path) -> Path | None:
    print(f"\n=== Processing {csv_path} ===")
    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"âš ï¸ cannot read CSV: {e}")
        return None
    if "manufacturer" not in df.columns or "name" not in df.columns:
        print("â„¹ï¸ skip (no 'manufacturer' or 'name')")
        return None

    # OpenAIè¨­å®š
    model = os.environ.get("OPENAI_MODEL", "gpt-4o-mini")
    api_key = os.environ.get("OPENAI_API_KEY")
    tr = Translator(model, api_key)

    # manufacturer_ja - è¾æ›¸å„ªå…ˆã€ãªã‘ã‚Œã°LLMâ†’è¾æ›¸è¿½åŠ 
    print("\nğŸ“‹ Translating manufacturers...")
    uniq_makers = list(set(df["manufacturer"].dropna().astype(str).unique()))
    
    # ã¾ãšè¾æ›¸ã§ãƒãƒƒãƒãƒ³ã‚°ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
    maker_ja_map = {}
    for val in uniq_makers:
        matched = next((DICT_ZH_TO_JA[k] for k in DICT_KEYS_SORTED if k in val), None)
        if matched:
            maker_ja_map[val] = matched
    
    # è¾æ›¸ã«ãªã„ã‚‚ã®ã‚’LLMã§ç¿»è¨³â†’è¾æ›¸ã«è¿½åŠ 
    need_llm_makers = [m for m in uniq_makers if m not in maker_ja_map]
    if need_llm_makers:
        llm_maker_map = translate_with_dict_update("manufacturer", need_llm_makers, {}, tr)
        maker_ja_map.update(llm_maker_map)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«é©ç”¨
    df["manufacturer_ja"] = df["manufacturer"].astype(str).map(lambda x: maker_ja_map.get(x, x))

    # global_name - è¾æ›¸å„ªå…ˆã€ãªã‘ã‚Œã°LLMâ†’è¾æ›¸è¿½åŠ ã€æœ€å¾Œã«ãƒ”ãƒ³ã‚¤ãƒ³
    print("\nğŸ“‹ Translating vehicle names...")
    uniq_names = list(set(df["name"].dropna().astype(str).unique()))
    
    # å›ºå®šè¾æ›¸ã‹ã‚‰ãƒãƒƒãƒãƒ³ã‚°
    name_map = {}
    for n in uniq_names:
        if n in DICT_GLOBAL_NAME:
            name_map[n] = DICT_GLOBAL_NAME[n]
    
    # è¾æ›¸ã«ãªã„ã‚‚ã®ã‚’LLMã§ç¿»è¨³â†’è¾æ›¸ã«è¿½åŠ 
    need_llm_names = [n for n in uniq_names if n not in name_map]
    if need_llm_names:
        llm_name_map = translate_with_dict_update("vehicle_name", need_llm_names, DICT_GLOBAL_NAME, tr)
        name_map.update(llm_name_map)
    
    # ãƒ”ãƒ³ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆLLMã§ç¿»è¨³ã§ããªã‹ã£ãŸã€ã¾ãŸã¯ä¸­å›½èªã®ã¿ã®å ´åˆï¼‰
    globals_ = []
    for n in df["name"].astype(str):
        g = name_map.get(n, "")
        # ä¸­å›½èªã®ã¿ã®å ´åˆã¯ãƒ”ãƒ³ã‚¤ãƒ³ã‚’è¿½åŠ 
        if not g or (g == n and re.search(r"[\u4e00-\u9fff]", g) and not re.search(r"[A-Za-z]", g)):
            g = add_block_pinyin_inline(n, g)
        globals_.append(g)
    
    insert_at = df.columns.get_loc("name") + 1
    df.insert(insert_at, "global_name", globals_)

    # âœ… ãƒ•ã‚¡ã‚¤ãƒ«åä¿®æ­£ï¼šæœ«å°¾ã® _with_maker ã‚’1å›ã ã‘é™¤å»
    base = re.sub(r"_with_maker$", "", csv_path.stem)
    out = csv_path.with_name(base + "_with_maker_with_maker_ja.csv")

    df.to_csv(out, index=False, encoding="utf-8-sig")
    print(f"âœ… saved: {out}  rows={len(df)}")
    return out

def main():
    if len(sys.argv) < 2:
        print("Usage: python tools/stage_translate_maker_to_ja.py <csv>")
        sys.exit(1)
    for arg in sys.argv[1:]:
        p = Path(arg)
        if p.exists() and p.suffix.lower() == ".csv":
            process_csv(p)

if __name__ == "__main__":
    main()
