# tools/translate_columns.py
# æ–¹é‡:
#  - ã‚»ã‚¯ã‚·ãƒ§ãƒ³_jaãƒ»é …ç›®_jaã¯è¾æ›¸ã®ã¿
#  - å€¤ã‚»ãƒ«ã¯LLMç¿»è¨³ï¼ˆä¾¡æ ¼è¡Œã¯ãƒ«ãƒ¼ãƒ«æ•´å½¢ã®ã¿ï¼‰
#  - ãƒ¢ãƒ‡ãƒ«åãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆ5åˆ—ç›®ä»¥é™ï¼‰ã‚‚ä¸­å›½èªãªã‚‰LLMç¿»è¨³
#  - YEAR_MINã§ãƒ¢ãƒ‡ãƒ«åˆ—ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæ—¢å®š: 2025ã€å³æ ¼åº¦ã¯YEAR_FILTER_STRICTã§èª¿æ•´ï¼‰
import os, re, json, time, pathlib, csv
import pandas as pd
from typing import List, Dict

# ========= å…¥å‡ºåŠ› =========
CSV_IN = os.environ.get("CSV_IN", "").strip()
if not CSV_IN:
    raise RuntimeError("CSV_IN ãŒæœªè¨­å®šã§ã™")
src_path = pathlib.Path(CSV_IN)
series_id = re.search(r"(\d+)", src_path.stem or src_path.name)
series_id = series_id.group(1) if series_id else "unknown"

OUT_DIR = src_path.parent
DST_PRIMARY   = OUT_DIR / f"{src_path.stem}.ja.csv"
DST_SECONDARY = OUT_DIR / f"{src_path.stem}_ja.csv"

# ========= è¨­å®š =========
MODEL   = os.environ.get("OPENAI_MODEL", "gpt-4.1-mini")
API_KEY = os.environ.get("OPENAI_API_KEY", "")

TRANSLATE_VALUES    = os.environ.get("TRANSLATE_VALUES", "true").lower() == "true"
TRANSLATE_COLNAMES  = os.environ.get("TRANSLATE_COLNAMES", "true").lower() == "true"
# æ—¢å®š: ãƒ˜ãƒƒãƒ€ãƒ¼ã®ãƒ—ãƒ¬ãƒ•ã‚£ã‚¯ã‚¹é™¤å»ã¯è¡Œã‚ãªã„ï¼ˆ=ãƒ•ãƒ«è¡¨è¨˜ç¶­æŒï¼‰
STRIP_GRADE_PREFIX  = os.environ.get("STRIP_GRADE_PREFIX", "false").lower() == "true"

# ãƒ¢ãƒ‡ãƒ«åˆ—ã®â€œå¹´å¼ãƒ•ã‚£ãƒ«ã‚¿â€
YEAR_MIN            = int(os.environ.get("YEAR_MIN", "2025"))
YEAR_FILTER_STRICT  = os.environ.get("YEAR_FILTER_STRICT", "true").lower() == "true"  # true=å¹´ãŒç„¡ã„åˆ—ã‚‚è½ã¨ã™, false=å¹´ä¸æ˜ã¯æ®‹ã™

EXRATE_CNY_TO_JPY   = float(os.environ.get("EXRATE_CNY_TO_JPY", "21.0"))

CACHE_REPO_DIR = pathlib.Path(os.environ.get("CACHE_REPO_DIR", "cache")).joinpath(series_id)
CACHE_REPO_DIR.mkdir(parents=True, exist_ok=True)

BATCH_SIZE, RETRIES, SLEEP_BASE = 60, 3, 1.2

# ========= ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»å›ºå®šè¨³ =========
NOISE_ANY = ["å¯¹æ¯”","å‚æ•°","å›¾ç‰‡","é…ç½®","è¯¦æƒ…"]
NOISE_PRICE_TAIL = ["è¯¢ä»·","è®¡ç®—å™¨","è¯¢åº•ä»·","æŠ¥ä»·","ä»·æ ¼è¯¢é—®","èµ·","èµ·å”®","åˆ°åº—","ç»é”€å•†"]

def clean_any_noise(s: str) -> str:
    s = str(s) if s is not None else ""
    for w in NOISE_ANY + NOISE_PRICE_TAIL:
        s = s.replace(w, "")
    return re.sub(r"\s+", " ", s).strip(" ã€€-â€”â€“")

def clean_price_cell(s: str) -> str:
    t = clean_any_noise(s)
    for w in NOISE_PRICE_TAIL:
        t = re.sub(rf"(?:\s*{re.escape(w)}\s*)+$", "", t)
    return t.strip()

RE_PAREN_ANY_YEN = re.compile(r"ï¼ˆ[^ï¼‰]*(?:æ—¥æœ¬å††|JPY|[Â¥ï¿¥]|å††)[^ï¼‰]*ï¼‰")
RE_ANY_YEN_TOKEN = re.compile(r"(æ—¥æœ¬å††|JPY|[Â¥ï¿¥]|å††)")
def strip_any_yen_tokens(s: str) -> str:
    t = str(s)
    t = RE_PAREN_ANY_YEN.sub("", t)
    t = RE_ANY_YEN_TOKEN.sub("", t)
    return re.sub(r"\s+", " ", t).strip()

def uniq(seq):
    s, out = set(), []
    for x in seq:
        if x not in s:
            s.add(x); out.append(x)
    return out

def chunked(xs, n):
    for i in range(0, len(xs), n):
        yield xs[i:i+n]

def parse_json_relaxed(content: str, terms: List[str]) -> Dict[str, str]:
    try:
        d = json.loads(content)
        if isinstance(d, dict) and "translations" in d:
            return {
                str(t["cn"]).strip(): str(t.get("ja", t["cn"])).strip()
                for t in d["translations"] if t.get("cn")
            }
    except Exception:
        pass
    pairs = re.findall(r'"cn"\s*:\s*"([^"]+)"\s*,\s*"ja"\s*:\s*"([^"]*)"', content)
    if pairs:
        return {cn.strip(): ja.strip() for cn, ja in pairs}
    return {t: t for t in terms}

# ========= LLM =========
class Translator:
    def __init__(self, model: str, api_key: str):
        if not (api_key and api_key.strip()):
            raise RuntimeError("OPENAI_API_KEY is not set")
        from openai import OpenAI
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.system_values = (
            "ã‚ãªãŸã¯è‡ªå‹•è»Šä»•æ§˜è¡¨ã®å°‚é–€ç¿»è¨³è€…ã§ã™ã€‚"
            "å…¥åŠ›ã¯ä¸­å›½èªã®ã€ã‚»ãƒ«å€¤ã€é…åˆ—ã€‚è‡ªç„¶ã§ç°¡æ½”ãªæ—¥æœ¬èªã¸ã€‚æ•°å€¤ã‚„AT/MTç­‰ã®è¨˜å·ã¯ä¿æŒã€‚"
            "å‡ºåŠ›ã¯ JSONï¼ˆ{'translations':[{'cn':'åŸæ–‡','ja':'è¨³æ–‡'}]}ï¼‰ã®ã¿ã€‚"
        )
        self.system_headers = (
            "ã‚ãªãŸã¯è‡ªå‹•è»Šã‚°ãƒ¬ãƒ¼ãƒ‰åã®å°‚é–€ç¿»è¨³è€…ã§ã™ã€‚"
            "å…¥åŠ›ã¯ä¸­å›½èªã®ã€ã‚°ãƒ¬ãƒ¼ãƒ‰/ãƒ¢ãƒ‡ãƒ«åã€é…åˆ—ã€‚å¹´å¼ã‚„æ’æ°—é‡ã€é§†å‹•è¨˜å·ï¼ˆ4MATIC ç­‰ï¼‰ã‚„è¨˜å·ã¯ä¿æŒã—ã€"
            "è‡ªç„¶ãªæ—¥æœ¬èªã¸å¤‰æ›ï¼ˆä¾‹ï¼šè¿åŠ¨å‹â†’ã‚¹ãƒãƒ¼ãƒ„ã€è±ªåå‹â†’ãƒ©ã‚°ã‚¸ãƒ¥ã‚¢ãƒªãƒ¼ï¼‰ã€‚"
            "å‡ºåŠ›ã¯ JSONï¼ˆ{'translations':[{'cn':'åŸæ–‡','ja':'è¨³æ–‡'}]}ï¼‰ã®ã¿ã€‚"
        )

    def _translate(self, terms: List[str], use_header_prompt: bool) -> Dict[str, str]:
        if not terms:
            return {}
        msgs = [
            {"role": "system", "content": self.system_headers if use_header_prompt else self.system_values},
            {"role": "user", "content": json.dumps({"terms": terms}, ensure_ascii=False)},
        ]
        resp = self.client.chat.completions.create(
            model=self.model, messages=msgs, temperature=0,
            response_format={"type": "json_object"},
        )
        content = resp.choices[0].message.content or ""
        return parse_json_relaxed(content, terms)

    def translate_values(self, unique_terms: List[str]) -> Dict[str, str]:
        out = {}
        for chunk in chunked(unique_terms, BATCH_SIZE):
            for attempt in range(1, RETRIES + 1):
                try:
                    out.update(self._translate(chunk, use_header_prompt=False))
                    break
                except Exception:
                    if attempt == RETRIES:
                        for t in chunk:
                            out.setdefault(t, t)
                    time.sleep(SLEEP_BASE * attempt)
        return out

    def translate_headers(self, unique_terms: List[str]) -> Dict[str, str]:
        out = {}
        for chunk in chunked(unique_terms, BATCH_SIZE):
            for attempt in range(1, RETRIES + 1):
                try:
                    out.update(self._translate(chunk, use_header_prompt=True))
                    break
                except Exception:
                    if attempt == RETRIES:
                        for t in chunk:
                            out.setdefault(t, t)
                    time.sleep(SLEEP_BASE * attempt)
        return out

# ========= å›ºå®šè¨³ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³/é …ç›®ã¯è¾æ›¸ã®ã¿ï¼‰ =========
FIX_JA_SECTIONS = {
    "è©²å½“ãªã—": "è©²å½“ãªã—",
    "åŸºæœ¬å‚æ•°": "åŸºæœ¬",
    "è½¦èº«": "ãƒœãƒ‡ã‚£",
    "å‘åŠ¨æœº": "ã‚¨ãƒ³ã‚¸ãƒ³",
    "å˜é€Ÿç®±": "ãƒˆãƒ©ãƒ³ã‚¹ãƒŸãƒƒã‚·ãƒ§ãƒ³",
    "åº•ç›˜è½¬å‘": "ã‚·ãƒ£ã‚·ãƒ¼ï¼ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°",
    "è½¦è½®åˆ¶åŠ¨": "ãƒ›ã‚¤ãƒ¼ãƒ«ï¼ãƒ–ãƒ¬ãƒ¼ã‚­",
    "è¢«åŠ¨å®‰å…¨": "å—å‹•å®‰å…¨è£…ç½®",
    "ä¸»åŠ¨å®‰å…¨": "èƒ½å‹•å®‰å…¨è£…ç½®",
    "é©¾é©¶æ“æ§": "ãƒ‰ãƒ©ã‚¤ãƒ“ãƒ³ã‚°ï¼æ“ç¸¦",
    "é©¾é©¶ç¡¬ä»¶": "é‹è»¢æ”¯æ´ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢",
    "é©¾é©¶åŠŸèƒ½": "é‹è»¢æ”¯æ´æ©Ÿèƒ½",
    "å¤–è§‚/é˜²ç›—": "å¤–è£…ï¼é˜²ç›—",
    "è½¦å¤–ç¯å…‰": "è»Šå¤–ç…§æ˜",
    "å¤©çª—/ç»ç’ƒ": "ã‚µãƒ³ãƒ«ãƒ¼ãƒ•ï¼ã‚¦ã‚¤ãƒ³ãƒ‰ã‚¦",
    "å¤–åè§†é•œ": "ãƒ‰ã‚¢ãƒŸãƒ©ãƒ¼",
    "å±å¹•/ç³»ç»Ÿ": "ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ï¼è»Šè¼‰ã‚·ã‚¹ãƒ†ãƒ ",
    "æ™ºèƒ½åŒ–é…ç½®": "ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆåŒ–",
    "æ–¹å‘ç›˜/å†…åè§†é•œ": "ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ï¼ãƒ«ãƒ¼ãƒ ãƒŸãƒ©ãƒ¼",
    "è½¦å†…å……ç”µ": "è»Šå†…å……é›»",
    "åº§æ¤…é…ç½®": "ã‚·ãƒ¼ãƒˆ",
    "éŸ³å“/è½¦å†…ç¯å…‰": "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªï¼å®¤å†…ç…§æ˜",
    "ç©ºè°ƒ/å†°ç®±": "ç©ºèª¿ï¼å†·è”µ",
    "é¢œè‰²": "ã‚«ãƒ©ãƒ¼",
    "é€‰è£…åŒ…": "ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸",
}

FIX_JA_ITEMS = {
    "å‚å•†æŒ‡å¯¼ä»·(å…ƒ)": "ãƒ¡ãƒ¼ã‚«ãƒ¼å¸Œæœ›å°å£²ä¾¡æ ¼",
    "ç»é”€å•†æŠ¥ä»·": "ãƒ‡ã‚£ãƒ¼ãƒ©ãƒ¼è²©å£²ä¾¡æ ¼ï¼ˆå…ƒï¼‰",
    "å‚å•†": "ãƒ¡ãƒ¼ã‚«ãƒ¼",
    "çº§åˆ«": "è»Šæ ¼",
    "èƒ½æºç±»å‹": "ç‡ƒæ–™ç¨®åˆ¥",
    "ç¯ä¿æ ‡å‡†": "æ’å‡ºã‚¬ã‚¹åŸºæº–",
    "ä¸Šå¸‚æ—¶é—´": "ç™ºå£²æ™‚æœŸ",
    "æœ€å¤§åŠŸç‡(kW)": "æœ€å¤§å‡ºåŠ›ï¼ˆkWï¼‰",
    "æœ€å¤§æ‰­çŸ©(NÂ·m)": "æœ€å¤§ãƒˆãƒ«ã‚¯ï¼ˆNÂ·mï¼‰",
    "å˜é€Ÿç®±": "ãƒˆãƒ©ãƒ³ã‚¹ãƒŸãƒƒã‚·ãƒ§ãƒ³",
    "è½¦èº«ç»“æ„": "ãƒœãƒ‡ã‚£æ§‹é€ ",
    "å‘åŠ¨æœº": "ã‚¨ãƒ³ã‚¸ãƒ³",
    "é•¿*å®½*é«˜(mm)": "å…¨é•·Ã—å…¨å¹…Ã—å…¨é«˜ï¼ˆmmï¼‰",
    "å®˜æ–¹0-100km/håŠ é€Ÿ(s)": "0-100km/håŠ é€Ÿï¼ˆå…¬å¼ï¼‰ï¼ˆsï¼‰",
    "æœ€é«˜è½¦é€Ÿ(km/h)": "æœ€é«˜é€Ÿåº¦ï¼ˆkm/hï¼‰",
    "WLTCç»¼åˆæ²¹è€—(L/100km)": "WLTCç·åˆç‡ƒè²»ï¼ˆL/100kmï¼‰",
    "æ•´è½¦è´¨ä¿": "è»Šä¸¡ä¿è¨¼",
    "æ•´å¤‡è´¨é‡(kg)": "è»Šä¸¡é‡é‡ï¼ˆkgï¼‰",
    "æœ€å¤§æ»¡è½½è´¨é‡(kg)": "æœ€å¤§ç·é‡é‡ï¼ˆkgï¼‰",
    "é•¿åº¦(mm)": "å…¨é•·ï¼ˆmmï¼‰",
    "å®½åº¦(mm)": "å…¨å¹…ï¼ˆmmï¼‰",
    "é«˜åº¦(mm)": "å…¨é«˜ï¼ˆmmï¼‰",
    "è½´è·(mm)": "ãƒ›ã‚¤ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼ˆmmï¼‰",
    "å‰è½®è·(mm)": "ãƒ•ãƒ­ãƒ³ãƒˆãƒˆãƒ¬ãƒƒãƒ‰ï¼ˆmmï¼‰",
    "åè½®è·(mm)": "ãƒªã‚¢ãƒˆãƒ¬ãƒƒãƒ‰ï¼ˆmmï¼‰",
    "æ¥è¿‘è§’(Â°)": "ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚¢ãƒ³ã‚°ãƒ«ï¼ˆÂ°ï¼‰",
    "ç¦»å»è§’(Â°)": "ãƒ‡ãƒ‘ãƒ¼ãƒãƒ£ãƒ¼ã‚¢ãƒ³ã‚°ãƒ«ï¼ˆÂ°ï¼‰",
    "è½¦é—¨å¼€å¯æ–¹å¼": "ãƒ‰ã‚¢é–‹é–‰æ–¹å¼",
    "è½¦é—¨æ•°(ä¸ª)": "ãƒ‰ã‚¢æ•°ï¼ˆæšï¼‰",
    "åº§ä½æ•°(ä¸ª)": "ä¹—è»Šå®šå“¡ï¼ˆåï¼‰",
    "æ²¹ç®±å®¹ç§¯(L)": "ç‡ƒæ–™ã‚¿ãƒ³ã‚¯å®¹é‡ï¼ˆLï¼‰",
    "åå¤‡å¢å®¹ç§¯(L)": "ãƒ©ã‚²ãƒƒã‚¸å®¹é‡ï¼ˆLï¼‰",
    "é£é˜»ç³»æ•°(Cd)": "ç©ºæ°—æŠµæŠ—ä¿‚æ•°ï¼ˆCdï¼‰",
    "å‘åŠ¨æœºå‹å·": "ã‚¨ãƒ³ã‚¸ãƒ³å‹å¼",
    "æ’é‡(mL)": "ç·æ’æ°—é‡ï¼ˆmLï¼‰",
    "æ’é‡(L)": "ç·æ’æ°—é‡ï¼ˆLï¼‰",
    "è¿›æ°”å½¢å¼": "éçµ¦æ–¹å¼",
    "å‘åŠ¨æœºå¸ƒå±€": "ã‚¨ãƒ³ã‚¸ãƒ³é…ç½®",
    "æ°”ç¼¸æ’åˆ—å½¢å¼": "ã‚·ãƒªãƒ³ãƒ€ãƒ¼é…åˆ—",
    "æ°”ç¼¸æ•°(ä¸ª)": "ã‚·ãƒªãƒ³ãƒ€ãƒ¼æ•°ï¼ˆå€‹ï¼‰",
    "æ¯ç¼¸æ°”é—¨æ•°(ä¸ª)": "1æ°—ç­’å½“ãŸã‚Šãƒãƒ«ãƒ–æ•°ï¼ˆå€‹ï¼‰",
    "é…æ°”æœºæ„": "ãƒãƒ«ãƒ–æ©Ÿæ§‹",
    "æœ€å¤§é©¬åŠ›(Ps)": "æœ€é«˜å‡ºåŠ›ï¼ˆPsï¼‰",
    "æœ€å¤§åŠŸç‡è½¬é€Ÿ(rpm)": "æœ€å¤§å‡ºåŠ›å›è»¢æ•°ï¼ˆrpmï¼‰",
    "æœ€å¤§æ‰­çŸ©è½¬é€Ÿ(rpm)": "æœ€å¤§ãƒˆãƒ«ã‚¯å›è»¢æ•°ï¼ˆrpmï¼‰",
    "æœ€å¤§å‡€åŠŸç‡(kW)": "æœ€å¤§æ­£å‘³å‡ºåŠ›ï¼ˆkWï¼‰",
    "ç‡ƒæ²¹æ ‡å·": "æ¨å¥¨ç‡ƒæ–™ã‚ªã‚¯ã‚¿ãƒ³ä¾¡",
    "ä¾›æ²¹æ–¹å¼": "ç‡ƒæ–™ä¾›çµ¦æ–¹å¼",
    "ç¼¸ç›–ææ–™": "ã‚·ãƒªãƒ³ãƒ€ãƒ¼ãƒ˜ãƒƒãƒ‰æè³ª",
    "ç¼¸ä½“ææ–™": "ã‚·ãƒªãƒ³ãƒ€ãƒ¼ãƒ–ãƒ­ãƒƒã‚¯æè³ª",
    "ç®€ç§°": "ç•¥ç§°",
    "æŒ¡ä½ä¸ªæ•°": "æ®µæ•°",
    "å˜é€Ÿç®±ç±»å‹": "ãƒˆãƒ©ãƒ³ã‚¹ãƒŸãƒƒã‚·ãƒ§ãƒ³å½¢å¼",
    "é©±åŠ¨æ–¹å¼": "é§†å‹•æ–¹å¼",
    "å››é©±å½¢å¼": "å››è¼ªé§†å‹•æ–¹å¼",
    "ä¸­å¤®å·®é€Ÿå™¨ç»“æ„": "ã‚»ãƒ³ã‚¿ãƒ¼ãƒ‡ãƒ•æ§‹é€ ",
    "å‰æ‚¬æ¶ç±»å‹": "ãƒ•ãƒ­ãƒ³ãƒˆã‚µã‚¹ãƒšãƒ³ã‚·ãƒ§ãƒ³å½¢å¼",
    "åæ‚¬æ¶ç±»å‹": "ãƒªã‚¢ã‚µã‚¹ãƒšãƒ³ã‚·ãƒ§ãƒ³å½¢å¼",
    "åŠ©åŠ›ç±»å‹": "ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ã‚¢ã‚·ã‚¹ãƒˆæ–¹å¼",
    "è½¦ä½“ç»“æ„": "ãƒ•ãƒ¬ãƒ¼ãƒ æ§‹é€ ",
    "å‰åˆ¶åŠ¨å™¨ç±»å‹": "ãƒ•ãƒ­ãƒ³ãƒˆãƒ–ãƒ¬ãƒ¼ã‚­å½¢å¼",
    "ååˆ¶åŠ¨å™¨ç±»å‹": "ãƒªã‚¢ãƒ–ãƒ¬ãƒ¼ã‚­å½¢å¼",
    "é©»è½¦åˆ¶åŠ¨ç±»å‹": "ãƒ‘ãƒ¼ã‚­ãƒ³ã‚°ãƒ–ãƒ¬ãƒ¼ã‚­å½¢å¼",
    "å‰è½®èƒè§„æ ¼": "ãƒ•ãƒ­ãƒ³ãƒˆã‚¿ã‚¤ãƒ¤ã‚µã‚¤ã‚º",
    "åè½®èƒè§„æ ¼": "ãƒªã‚¢ã‚¿ã‚¤ãƒ¤ã‚µã‚¤ã‚º",
    "å¤‡èƒè§„æ ¼": "ã‚¹ãƒšã‚¢ã‚¿ã‚¤ãƒ¤ä»•æ§˜",
    "ä¸»/å‰¯é©¾é©¶åº§å®‰å…¨æ°”å›Š": "é‹è»¢å¸­ï¼åŠ©æ‰‹å¸­ã‚¨ã‚¢ãƒãƒƒã‚°",
    "å‰/åæ’ä¾§æ°”å›Š": "å‰å¸­ï¼å¾Œå¸­ã‚µã‚¤ãƒ‰ã‚¨ã‚¢ãƒãƒƒã‚°",
    "å‰/åæ’å¤´éƒ¨æ°”å›Š(æ°”å¸˜)": "å‰å¾Œå¸­ã‚«ãƒ¼ãƒ†ãƒ³ã‚¨ã‚¢ãƒãƒƒã‚°",
    "è†éƒ¨æ°”å›Š": "ãƒ‹ãƒ¼ã‚¨ã‚¢ãƒãƒƒã‚°",
    "å‰æ’ä¸­é—´æ°”å›Š": "å‰å¸­ã‚»ãƒ³ã‚¿ãƒ¼ã‚¨ã‚¢ãƒãƒƒã‚°",
    "è¢«åŠ¨è¡Œäººä¿æŠ¤": "æ­©è¡Œè€…ä¿è­·ï¼ˆå—å‹•ï¼‰",
    "ABSé˜²æŠ±æ­»": "ABSï¼ˆã‚¢ãƒ³ãƒãƒ­ãƒƒã‚¯ãƒ–ãƒ¬ãƒ¼ã‚­ï¼‰",
    "åˆ¶åŠ¨åŠ›åˆ†é…(EBD/CBCç­‰)": "åˆ¶å‹•åŠ›é…åˆ†ï¼ˆEBD/CBCç­‰ï¼‰",
    "åˆ¹è½¦è¾…åŠ©(EBA/BAS/BAç­‰)": "ãƒ–ãƒ¬ãƒ¼ã‚­ã‚¢ã‚·ã‚¹ãƒˆï¼ˆEBA/BAS/BAç­‰ï¼‰",
    "ç‰µå¼•åŠ›æ§åˆ¶(ASR/TCS/TRCç­‰)": "ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ï¼ˆASR/TCS/TRCç­‰ï¼‰",
    "è½¦èº«ç¨³å®šæ§åˆ¶(ESC/ESP/DSCç­‰)": "è»Šä¸¡å®‰å®šåˆ¶å¾¡ï¼ˆESC/ESP/DSCç­‰ï¼‰",
    "èƒå‹ç›‘æµ‹åŠŸèƒ½": "ã‚¿ã‚¤ãƒ¤ç©ºæ°—åœ§ç›£è¦–",
    "å®‰å…¨å¸¦æœªç³»æé†’": "ã‚·ãƒ¼ãƒˆãƒ™ãƒ«ãƒˆéè£…ç€è­¦å ±",
    "ISOFIXå„¿ç«¥åº§æ¤…æ¥å£": "ISOFIXãƒãƒ£ã‚¤ãƒ«ãƒ‰ã‚·ãƒ¼ãƒˆå›ºå®šå…·",
    "è½¦é“åç¦»é¢„è­¦ç³»ç»Ÿ": "è»Šç·šé€¸è„±è­¦å ±",
    "ä¸»åŠ¨åˆ¹è½¦/ä¸»åŠ¨å®‰å…¨ç³»ç»Ÿ": "è‡ªå‹•ç·Šæ€¥ãƒ–ãƒ¬ãƒ¼ã‚­ï¼ˆAEBï¼‰",
    "ç–²åŠ³é©¾é©¶æç¤º": "ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ç–²åŠ´è­¦å ±",
    "å‰æ–¹ç¢°æ’é¢„è­¦": "å‰æ–¹è¡çªè­¦å ±",
    "å†…ç½®è¡Œè½¦è®°å½•ä»ª": "ãƒ‰ãƒ©ã‚¤ãƒ–ãƒ¬ã‚³ãƒ¼ãƒ€ãƒ¼å†…è”µ",
    "é“è·¯æ•‘æ´å‘¼å«": "ãƒ­ãƒ¼ãƒ‰ã‚¢ã‚·ã‚¹ãƒˆã‚³ãƒ¼ãƒ«",
    "é©¾é©¶æ¨¡å¼åˆ‡æ¢": "ãƒ‰ãƒ©ã‚¤ãƒ“ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰åˆ‡æ›¿",
    "å‘åŠ¨æœºå¯åœæŠ€æœ¯": "ã‚¢ã‚¤ãƒ‰ãƒªãƒ³ã‚°ã‚¹ãƒˆãƒƒãƒ—",
    "è‡ªåŠ¨é©»è½¦": "ã‚ªãƒ¼ãƒˆãƒ›ãƒ¼ãƒ«ãƒ‰",
    "ä¸Šå¡è¾…åŠ©": "ãƒ’ãƒ«ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ã‚·ã‚¹ãƒˆ",
    "å¯å˜æ‚¬æ¶åŠŸèƒ½": "å¯å¤‰ã‚µã‚¹ãƒšãƒ³ã‚·ãƒ§ãƒ³æ©Ÿèƒ½",
    "å¯å˜è½¬å‘æ¯”": "å¯å¤‰ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°æ¯”",
    "å‰/åé©»è½¦é›·è¾¾": "å‰å¾Œãƒ‘ãƒ¼ã‚­ãƒ³ã‚°ã‚»ãƒ³ã‚µãƒ¼",
    "é©¾é©¶è¾…åŠ©å½±åƒ": "å‘¨å›²ç›£è¦–ã‚«ãƒ¡ãƒ©",
    "å‰æ–¹æ„ŸçŸ¥æ‘„åƒå¤´": "å‰æ–¹æ¤œçŸ¥ã‚«ãƒ¡ãƒ©",
    "æ‘„åƒå¤´æ•°é‡": "ã‚«ãƒ¡ãƒ©æ•°",
    "è½¦å†…æ‘„åƒå¤´æ•°é‡": "è»Šå†…ã‚«ãƒ¡ãƒ©æ•°",
    "è¶…å£°æ³¢é›·è¾¾æ•°é‡": "è¶…éŸ³æ³¢ã‚»ãƒ³ã‚µãƒ¼æ•°",
    "å·¡èˆªç³»ç»Ÿ": "ã‚¯ãƒ«ãƒ¼ã‚ºåˆ¶å¾¡",
    "è¾…åŠ©é©¾é©¶ç­‰çº§": "é‹è»¢æ”¯æ´ãƒ¬ãƒ™ãƒ«",
    "å«æ˜Ÿå¯¼èˆªç³»ç»Ÿ": "ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ",
    "å¯¼èˆªè·¯å†µä¿¡æ¯æ˜¾ç¤º": "äº¤é€šæƒ…å ±è¡¨ç¤º",
    "åœ°å›¾å“ç‰Œ": "åœ°å›³ãƒ–ãƒ©ãƒ³ãƒ‰",
    "ARå®æ™¯å¯¼èˆª": "ARå®Ÿå†™ãƒŠãƒ“",
    "å¹¶çº¿è¾…åŠ©": "è»Šç·šå¤‰æ›´æ”¯æ´",
    "è½¦é“ä¿æŒè¾…åŠ©ç³»ç»Ÿ": "è»Šç·šç¶­æŒæ”¯æ´",
    "è½¦é“å±…ä¸­ä¿æŒ": "è»Šç·šä¸­å¤®ç¶­æŒ",
    "é“è·¯äº¤é€šæ ‡è¯†è¯†åˆ«": "äº¤é€šæ¨™è­˜èªè­˜",
    "è¾…åŠ©æ³Šè½¦å…¥ä½": "é§è»Šæ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ",
    "è¾…åŠ©å˜é“": "è‡ªå‹•è»Šç·šå¤‰æ›´æ”¯æ´",
    "è¾…åŠ©åŒé“è‡ªåŠ¨é©¶å‡º(å…¥)": "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒã‚§ãƒ³ã‚¸å‡ºå…¥æ”¯æ´",
    "è¾…åŠ©é©¾é©¶è·¯æ®µ": "æ”¯æ´å¯¾å¿œè·¯ç¨®",
    "å¤–è§‚å¥—ä»¶": "ã‚¨ã‚¯ã‚¹ãƒ†ãƒªã‚¢ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸",
    "è½®åœˆæè´¨": "ãƒ›ã‚¤ãƒ¼ãƒ«æè³ª",
    "ç”µåŠ¨åå¤‡å¢": "é›»å‹•ãƒ†ãƒ¼ãƒ«ã‚²ãƒ¼ãƒˆ",
    "æ„Ÿåº”åå¤‡å¢": "ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ãƒ†ãƒ¼ãƒ«ã‚²ãƒ¼ãƒˆ",
    "ç”µåŠ¨åå¤‡å¢ä½ç½®è®°å¿†": "ãƒ†ãƒ¼ãƒ«ã‚²ãƒ¼ãƒˆé–‹åº¦è¨˜æ†¶",
    "å‘åŠ¨æœºç”µå­é˜²ç›—": "ã‚¨ãƒ³ã‚¸ãƒ³ã‚¤ãƒ¢ãƒ“ãƒ©ã‚¤ã‚¶ãƒ¼",
    "è½¦å†…ä¸­æ§é”": "é›†ä¸­ãƒ‰ã‚¢ãƒ­ãƒƒã‚¯",
    "é’¥åŒ™ç±»å‹": "ã‚­ãƒ¼ã‚¿ã‚¤ãƒ—",
    "æ— é’¥åŒ™å¯åŠ¨ç³»ç»Ÿ": "ã‚­ãƒ¼ãƒ¬ã‚¹å§‹å‹•ã‚·ã‚¹ãƒ†ãƒ ",
    "æ— é’¥åŒ™è¿›å…¥åŠŸèƒ½": "ã‚­ãƒ¼ãƒ¬ã‚¹ã‚¨ãƒ³ãƒˆãƒªãƒ¼",
    "éšè—ç”µåŠ¨é—¨æŠŠæ‰‹": "æ ¼ç´å¼ãƒ‰ã‚¢ãƒãƒ³ãƒ‰ãƒ«",
    "è¿œç¨‹å¯åŠ¨åŠŸèƒ½": "ãƒªãƒ¢ãƒ¼ãƒˆã‚¹ã‚¿ãƒ¼ãƒˆ",
    "è¿‘å…‰ç¯å…‰æº": "ãƒ­ãƒ¼ãƒ“ãƒ¼ãƒ å…‰æº",
    "è¿œå…‰ç¯å…‰æº": "ãƒã‚¤ãƒ“ãƒ¼ãƒ å…‰æº",
    "ç¯å…‰ç‰¹è‰²åŠŸèƒ½": "ãƒ©ã‚¤ãƒˆç‰¹åˆ¥æ©Ÿèƒ½",
    "LEDæ—¥é—´è¡Œè½¦ç¯": "LEDãƒ‡ã‚¤ã‚¿ã‚¤ãƒ ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãƒ©ã‚¤ãƒˆ",
    "è‡ªé€‚åº”è¿œè¿‘å…‰": "ã‚¢ãƒ€ãƒ—ãƒ†ã‚£ãƒ–ãƒã‚¤ãƒ“ãƒ¼ãƒ ",
    "è‡ªåŠ¨å¤´ç¯": "ã‚ªãƒ¼ãƒˆãƒ©ã‚¤ãƒˆ",
    "è½¬å‘å¤´ç¯": "ã‚³ãƒ¼ãƒŠãƒªãƒ³ã‚°ãƒ©ã‚¤ãƒˆ",
    "è½¦å‰é›¾ç¯": "ãƒ•ãƒ­ãƒ³ãƒˆãƒ•ã‚©ã‚°ãƒ©ãƒ³ãƒ—",
    "å¤§ç¯é«˜åº¦å¯è°ƒ": "ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒˆãƒ¬ãƒ™ãƒ©ã‚¤ã‚¶ãƒ¼",
    "å¤§ç¯å»¶æ—¶å…³é—­": "ãƒ©ã‚¤ãƒˆã‚ªãƒ•ãƒ‡ã‚£ãƒ¬ã‚¤",
    "å¤©çª—ç±»å‹": "ã‚µãƒ³ãƒ«ãƒ¼ãƒ•å½¢å¼",
    "å‰/åç”µåŠ¨è½¦çª—": "å‰å¾Œãƒ‘ãƒ¯ãƒ¼ã‚¦ã‚¤ãƒ³ãƒ‰ã‚¦",
    "è½¦çª—ä¸€é”®å‡é™åŠŸèƒ½": "ãƒ¯ãƒ³ã‚¿ãƒƒãƒã‚¦ã‚¤ãƒ³ãƒ‰ã‚¦",
    "è½¦çª—é˜²å¤¹æ‰‹åŠŸèƒ½": "æŒŸã¿è¾¼ã¿é˜²æ­¢æ©Ÿæ§‹",
    "ä¾§çª—å¤šå±‚éš”éŸ³ç»ç’ƒ": "å¤šå±¤é®éŸ³ã‚¬ãƒ©ã‚¹ï¼ˆã‚µã‚¤ãƒ‰ï¼‰",
    "åé£æŒ¡é®é˜³å¸˜": "ãƒªã‚¢ã‚¦ã‚¤ãƒ³ãƒ‰ã‚¦ã‚µãƒ³ã‚·ã‚§ãƒ¼ãƒ‰",
    "åæ’ä¾§çª—é®é˜³å¸˜": "å¾Œå¸­ã‚µã‚¤ãƒ‰ã‚µãƒ³ã‚·ã‚§ãƒ¼ãƒ‰",
    "è½¦å†…åŒ–å¦†é•œ": "ãƒãƒ‹ãƒ†ã‚£ãƒŸãƒ©ãƒ¼",
    "åé›¨åˆ·": "ãƒªã‚¢ãƒ¯ã‚¤ãƒ‘ãƒ¼",
    "æ„Ÿåº”é›¨åˆ·åŠŸèƒ½": "ãƒ¬ã‚¤ãƒ³ã‚»ãƒ³ã‚µãƒ¼",
    "å¤–åè§†é•œåŠŸèƒ½": "ãƒ‰ã‚¢ãƒŸãƒ©ãƒ¼æ©Ÿèƒ½",
    "ä¸­æ§å½©è‰²å±å¹•": "ã‚»ãƒ³ã‚¿ãƒ¼ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤",
    "ä¸­æ§å±å¹•å°ºå¯¸": "ã‚»ãƒ³ã‚¿ãƒ¼ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚µã‚¤ã‚º",
    "å‰¯é©¾å¨±ä¹å±å°ºå¯¸": "åŠ©æ‰‹å¸­ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã‚µã‚¤ã‚º",
    "è“ç‰™/è½¦è½½ç”µè¯": "Bluetoothï¼è»Šè¼‰é›»è©±",
    "æ‰‹æœºäº’è”/æ˜ å°„": "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³é€£æºï¼ãƒŸãƒ©ãƒ¼ãƒªãƒ³ã‚°",
    "è¯­éŸ³è¯†åˆ«æ§åˆ¶ç³»ç»Ÿ": "éŸ³å£°èªè­˜ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«",
    "è¯­éŸ³åŠ©æ‰‹å”¤é†’è¯": "éŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆèµ·å‹•èª",
    "è¯­éŸ³å…å”¤é†’è¯": "ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒ¬ã‚¹éŸ³å£°æ“ä½œ",
    "è¯­éŸ³åˆ†åŒºåŸŸå”¤é†’è¯†åˆ«": "ã‚¨ãƒªã‚¢åˆ¥éŸ³å£°èµ·å‹•èªè­˜",
    "è¯­éŸ³è¿ç»­è¯†åˆ«": "é€£ç¶šéŸ³å£°èªè­˜",
    "å¯è§å³å¯è¯´": "è¦–è¦šé€£å‹•éŸ³å£°æ“ä½œ",
    "æ‰‹åŠ¿æ§åˆ¶": "ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«",
    "åº”ç”¨å•†åº—": "ã‚¢ãƒ—ãƒªã‚¹ãƒˆã‚¢",
    "è½¦è½½æ™ºèƒ½ç³»ç»Ÿ": "è»Šè¼‰OSï¼ã‚¤ãƒ³ãƒ•ã‚©ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ",
    "è½¦æœºæ™ºèƒ½èŠ¯ç‰‡": "è»Šè¼‰SoC",
    "è½¦è”ç½‘": "è»Šè¼‰é€šä¿¡ï¼ˆã‚³ãƒã‚¯ãƒ†ãƒƒãƒ‰ï¼‰",
    "4G/5Gç½‘ç»œ": "4G/5Gé€šä¿¡",
    "OTAå‡çº§": "OTAã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ",
    "V2Xé€šè®¯": "V2Xé€šä¿¡",
    "æ‰‹æœºAPPè¿œç¨‹åŠŸèƒ½": "ã‚¹ãƒãƒ›ã‚¢ãƒ—ãƒªé éš”æ©Ÿèƒ½",
    "æ–¹å‘ç›˜æè´¨": "ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°æè³ª",
    "æ–¹å‘ç›˜ä½ç½®è°ƒèŠ‚": "ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ä½ç½®èª¿æ•´",
    "æ¢æŒ¡å½¢å¼": "ã‚·ãƒ•ãƒˆå½¢å¼",
    "å¤šåŠŸèƒ½æ–¹å‘ç›˜": "ãƒãƒ«ãƒãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°",
    "æ–¹å‘ç›˜æ¢æŒ¡æ‹¨ç‰‡": "ãƒ‘ãƒ‰ãƒ«ã‚·ãƒ•ãƒˆ",
    "æ–¹å‘ç›˜åŠ çƒ­": "ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ãƒ’ãƒ¼ã‚¿ãƒ¼",
    "æ–¹å‘ç›˜è®°å¿†": "ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ãƒ¡ãƒ¢ãƒªãƒ¼",
    "è¡Œè½¦ç”µè„‘æ˜¾ç¤ºå±å¹•": "ãƒ‰ãƒ©ã‚¤ãƒ–ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿è¡¨ç¤º",
    "å…¨æ¶²æ™¶ä»ªè¡¨ç›˜": "ãƒ•ãƒ«æ¶²æ™¶ãƒ¡ãƒ¼ã‚¿ãƒ¼ãƒ‘ãƒãƒ«",
    "æ¶²æ™¶ä»ªè¡¨å°ºå¯¸": "ãƒ¡ãƒ¼ã‚¿ãƒ¼æ¶²æ™¶ã‚µã‚¤ã‚º",
    "HUDæŠ¬å¤´æ•°å­—æ˜¾ç¤º": "ãƒ˜ãƒƒãƒ‰ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ï¼ˆHUDï¼‰",
    "å†…åè§†é•œåŠŸèƒ½": "ãƒ«ãƒ¼ãƒ ãƒŸãƒ©ãƒ¼æ©Ÿèƒ½",
    "ETCè£…ç½®": "ETCè£…ç½®",
    "å¤šåª’ä½“/å……ç”µæ¥å£": "ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢ï¼å……é›»ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹",
    "USB/Type-Cæ¥å£æ•°é‡": "USB/Type-Cãƒãƒ¼ãƒˆæ•°",
    "æ‰‹æœºæ— çº¿å……ç”µåŠŸèƒ½": "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹å……é›»",
    "åº§æ¤…æè´¨": "ã‚·ãƒ¼ãƒˆæè³ª",
    "ä¸»åº§æ¤…è°ƒèŠ‚æ–¹å¼": "é‹è»¢å¸­èª¿æ•´æ–¹å¼",
    "å‰¯åº§æ¤…è°ƒèŠ‚æ–¹å¼": "åŠ©æ‰‹å¸­èª¿æ•´æ–¹å¼",
    "ä¸»/å‰¯é©¾é©¶åº§ç”µåŠ¨è°ƒèŠ‚": "é‹è»¢å¸­ï¼åŠ©æ‰‹å¸­é›»å‹•èª¿æ•´",
    "å‰æ’åº§æ¤…åŠŸèƒ½": "å‰å¸­ã‚·ãƒ¼ãƒˆæ©Ÿèƒ½",
    "ç”µåŠ¨åº§æ¤…è®°å¿†åŠŸèƒ½": "é›»å‹•ã‚·ãƒ¼ãƒˆãƒ¡ãƒ¢ãƒªãƒ¼",
    "å‰¯é©¾é©¶ä½åæ’å¯è°ƒèŠ‚æŒ‰é’®": "åŠ©æ‰‹å¸­å¾Œå¸­èª¿æ•´ãƒœã‚¿ãƒ³",
    "ç¬¬äºŒæ’åº§æ¤…è°ƒèŠ‚": "å¾Œå¸­èª¿æ•´æ©Ÿèƒ½",
    "ç¬¬äºŒæ’åº§æ¤…ç”µåŠ¨è°ƒèŠ‚": "å¾Œå¸­é›»å‹•èª¿æ•´",
    "ç¬¬äºŒæ’åº§æ¤…åŠŸèƒ½": "å¾Œå¸­ã‚·ãƒ¼ãƒˆæ©Ÿèƒ½",
    "åæ’åº§æ¤…æ”¾å€’å½¢å¼": "å¾Œå¸­å¯å€’æ–¹å¼",
    "å‰/åä¸­å¤®æ‰¶æ‰‹": "å‰å¾Œã‚»ãƒ³ã‚¿ãƒ¼ã‚¢ãƒ¼ãƒ ãƒ¬ã‚¹ãƒˆ",
    "åæ’æ¯æ¶": "å¾Œå¸­ã‚«ãƒƒãƒ—ãƒ›ãƒ«ãƒ€ãƒ¼",
    "æ‰¬å£°å™¨å“ç‰Œåç§°": "ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒ–ãƒ©ãƒ³ãƒ‰",
    "æ‰¬å£°å™¨æ•°é‡": "ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼æ•°",
    "æœæ¯”å…¨æ™¯å£°(Dolby Atmos)": "Dolby Atmos",
    "è½¦å†…ç¯å¢ƒæ°›å›´ç¯": "ã‚¢ãƒ³ãƒ“ã‚¨ãƒ³ãƒˆãƒ©ã‚¤ãƒˆ",
    "ä¸»åŠ¨å¼ç¯å¢ƒæ°›å›´ç¯": "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ³ãƒ“ã‚¨ãƒ³ãƒˆãƒ©ã‚¤ãƒˆ",
    "ç©ºè°ƒæ¸©åº¦æ§åˆ¶æ–¹å¼": "ç©ºèª¿æ¸©åº¦åˆ¶å¾¡æ–¹å¼",
    "åæ’ç‹¬ç«‹ç©ºè°ƒ": "å¾Œå¸­ç‹¬ç«‹ç©ºèª¿",
    "ååº§å‡ºé£å£": "å¾Œå¸­ã‚¨ã‚¢ã‚¢ã‚¦ãƒˆãƒ¬ãƒƒãƒˆ",
    "æ¸©åº¦åˆ†åŒºæ§åˆ¶": "æ¸©åº¦ç‹¬ç«‹èª¿æ•´ï¼ˆã‚¾ãƒ¼ãƒ³ï¼‰",
    "è½¦è½½ç©ºæ°”å‡€åŒ–å™¨": "è»Šè¼‰ç©ºæ°—æ¸…æµ„æ©Ÿ",
    "è½¦å†…PM2.5è¿‡æ»¤è£…ç½®": "è»Šå†…PM2.5ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼",
    "ç©ºæ°”è´¨é‡ç›‘æµ‹": "ç©ºæ°—è³ªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°",
    "å¤–è§‚é¢œè‰²": "å¤–è£…è‰²",
    "å†…é¥°é¢œè‰²": "å†…è£…è‰²",
    "æ™ºäº«å¥—è£…2": "ã‚¹ãƒãƒ¼ãƒˆã‚³ãƒ³ãƒ•ã‚©ãƒ¼ãƒˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸2",
}

PRICE_ITEM_MSRP_CN   = {"å‚å•†æŒ‡å¯¼ä»·(å…ƒ)","å‚å•†æŒ‡å¯¼ä»·","å‚å•†å»ºè®®é›¶å”®ä»·"}
PRICE_ITEM_DEALER_CN = {"ç»é”€å•†æŠ¥ä»·","ç»é”€å•†å‚è€ƒä»·","ç»é”€å•†"}

def norm_cn_cell(s: str) -> str:
    return re.sub(r"\s+", "", str(s or "")).strip()

# ========= ä¾¡æ ¼æ•´å½¢ =========
RE_WAN = re.compile(r"(\d+(?:\.\d+)?)\s*ä¸‡")
RE_NUM = re.compile(r"(\d+(?:\.\d+)?)")
def _parse_cny_amount(cell: str) -> float | None:
    t = clean_price_cell(cell)
    m = RE_WAN.search(t)
    if m:
        return float(m.group(1)) * 10000.0
    m = RE_NUM.search(t)
    if m:
        return float(m.group(1))
    return None

def msrp_to_yuan_and_jpy(cell: str, rate: float) -> str:
    t = strip_any_yen_tokens(clean_price_cell(cell))
    amt = _parse_cny_amount(t)
    if amt is None:
        return t
    jpy = int(round(amt * rate))
    if "ä¸‡" in t and "å…ƒ" not in t:
        t = f"{t}å…ƒ"
    return f"{t}ï¼ˆæ—¥æœ¬å††{jpy:,}å††ï¼‰"

def dealer_to_yuan_only(cell: str) -> str:
    t = strip_any_yen_tokens(clean_price_cell(cell))
    if not t or t in {"-","â€“","â€”"}:
        return t
    if ("å…ƒ" not in t) and RE_WAN.search(t):
        t = f"{t}å…ƒ"
    return t

# ========= ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ— å‰ç½®èªé™¤å»ï¼ˆå¿…è¦æ™‚ã®ã¿ï¼‰ =========
def strip_grade_prefix(name: str) -> str:
    s = str(name)
    if not STRIP_GRADE_PREFIX:
        return s
    # å…·ä½“ãƒ«ãƒ¼ãƒ«ãŒå¿…è¦ãªå ´åˆã®ã¿é©ç”¨ï¼ˆæ—¢å®šã¯ä½•ã‚‚ã—ãªã„ï¼‰
    s = re.sub(r"^[^,ï¼Œ\s]{1,40}\s*\d{4}æ¬¾\s*æ”¹æ¬¾\s*", "", s).strip()
    return s

def extract_year(name: str) -> int | None:
    m = re.search(r"\b(20\d{2})\b", str(name))
    return int(m.group(1)) if m else None

# ========= å®Ÿå‡¦ç† =========
df = pd.read_csv(src_path, dtype=str).fillna("")
prev_cn_path = CACHE_REPO_DIR / "config_cn_snapshot.csv"
prev_ja_path = CACHE_REPO_DIR / "config_ja_prev.csv"
prev_cn_df = pd.read_csv(prev_cn_path, dtype=str).fillna("") if prev_cn_path.exists() else None
prev_ja_df = pd.read_csv(prev_ja_path, dtype=str).fillna("") if prev_ja_path.exists() else None
enable_reuse = (prev_cn_df is not None) and (prev_ja_df is not None)

# ---- ãƒ¢ãƒ‡ãƒ«åˆ—ï¼ˆ5åˆ—ç›®ä»¥é™ï¼‰: å¹´å¼ãƒ•ã‚£ãƒ«ã‚¿ & ãƒ˜ãƒƒãƒ€ãƒ¼ç¿»è¨³ ----
columns = list(df.columns)
fixed_cols = columns[:4]
model_cols = columns[4:]

# å¹´å¼ãƒ•ã‚£ãƒ«ã‚¿
def keep_col(colname: str) -> bool:
    y = extract_year(colname)
    if y is None:
        return not YEAR_FILTER_STRICT  # å³æ ¼ãªã‚‰è½ã¨ã™ / éå³æ ¼ãªã‚‰æ®‹ã™
    return y >= YEAR_MIN

kept_model_cols = [c for c in model_cols if keep_col(c)]
df = df[fixed_cols + kept_model_cols]

# ãƒ˜ãƒƒãƒ€ãƒ¼æ•´å½¢ï¼ˆstripã¯æ—¢å®šOFFï¼‰
if TRANSLATE_COLNAMES and kept_model_cols:
    zh_char = re.compile(r"[\u4e00-\u9fff]")
    # LLMç¿»è¨³å¯¾è±¡ï¼ˆä¸­å›½èªã‚’å«ã‚€ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã¿ï¼‰
    headers_to_tr = [c for c in kept_model_cols if zh_char.search(c)]
    header_map = {}
    if headers_to_tr and API_KEY.strip():
        tr = Translator(MODEL, API_KEY)
        header_map = tr.translate_headers(uniq(headers_to_tr))
    # ç½®æ›ï¼ˆLLMã§è¿”ã‚‰ãªã‘ã‚Œã°å…ƒã®ã¾ã¾ï¼‰
    new_model_cols = []
    for c in kept_model_cols:
        cc = strip_grade_prefix(c)
        if c in header_map:
            cc = header_map[c] or cc
        new_model_cols.append(cc)
    df.columns = fixed_cols + new_model_cols

# ---- ã‚»ã‚¯ã‚·ãƒ§ãƒ³/é …ç›®ï¼šè¾æ›¸ã®ã¿ï¼ˆLLMä¸ä½¿ç”¨ï¼‰ ----
sec_map_old, item_map_old = {}, {}
if enable_reuse:
    if "ã‚»ã‚¯ã‚·ãƒ§ãƒ³_ja" in prev_ja_df.columns:
        for cur, old_cn, old_ja in zip(df["ã‚»ã‚¯ã‚·ãƒ§ãƒ³"].astype(str),
                                       prev_cn_df["ã‚»ã‚¯ã‚·ãƒ§ãƒ³"].astype(str),
                                       prev_ja_df["ã‚»ã‚¯ã‚·ãƒ§ãƒ³_ja"].astype(str)):
            if norm_cn_cell(cur) == norm_cn_cell(old_cn):
                sec_map_old[str(cur).strip()] = str(old_ja).strip() or str(cur).strip()
    if "é …ç›®_ja" in prev_ja_df.columns:
        for cur, old_cn, old_ja in zip(df["é …ç›®"].astype(str),
                                       prev_cn_df["é …ç›®"].astype(str),
                                       prev_ja_df["é …ç›®_ja"].astype(str)):
            if norm_cn_cell(cur) == norm_cn_cell(old_cn):
                item_map_old[str(cur).strip()] = str(old_ja).strip() or str(cur).strip()

sec_map  = dict(sec_map_old);  sec_map.update(FIX_JA_SECTIONS)
item_map = dict(item_map_old); item_map.update(FIX_JA_ITEMS)

out_full = df.copy()
out_full.insert(1, "ã‚»ã‚¯ã‚·ãƒ§ãƒ³_ja", out_full["ã‚»ã‚¯ã‚·ãƒ§ãƒ³"].map(lambda s: sec_map.get(str(s).strip(), str(s).strip())))
out_full.insert(3, "é …ç›®_ja",     out_full["é …ç›®"].map(lambda s: item_map.get(str(s).strip(), str(s).strip())))

# è¦‹å‡ºã—ï¼ˆä¾¡æ ¼åï¼‰ã®ã‚†ã‚‰ãè£œæ­£
PAREN_CURR_RE = re.compile(r"ï¼ˆ\s*(?:å††|å…ƒ|äººæ°‘å…ƒ|CNY|RMB|JPY)[^ï¼‰]*ï¼‰")
out_full["é …ç›®_ja"] = out_full["é …ç›®_ja"].astype(str).str.replace(PAREN_CURR_RE, "", regex=True).str.strip()
out_full.loc[out_full["é …ç›®_ja"].str.match(r"^ãƒ¡ãƒ¼ã‚«ãƒ¼å¸Œæœ›å°å£²ä¾¡æ ¼.*$", na=False), "é …ç›®_ja"] = "ãƒ¡ãƒ¼ã‚«ãƒ¼å¸Œæœ›å°å£²ä¾¡æ ¼"
out_full.loc[out_full["é …ç›®_ja"].str.contains(r"ãƒ‡ã‚£ãƒ¼ãƒ©ãƒ¼è²©å£²ä¾¡æ ¼", na=False), "é …ç›®_ja"] = "ãƒ‡ã‚£ãƒ¼ãƒ©ãƒ¼è²©å£²ä¾¡æ ¼ï¼ˆå…ƒï¼‰"

# ä¾¡æ ¼ã‚»ãƒ«æ•´å½¢ï¼ˆç¿»è¨³ã—ãªã„ï¼‰
MSRP_JA_RE   = re.compile(r"^ãƒ¡ãƒ¼ã‚«ãƒ¼å¸Œæœ›å°å£²ä¾¡æ ¼$")
DEALER_JA_RE = re.compile(r"^ãƒ‡ã‚£ãƒ¼ãƒ©ãƒ¼è²©å£²ä¾¡æ ¼ï¼ˆå…ƒï¼‰$")
is_msrp   = out_full["é …ç›®"].isin(PRICE_ITEM_MSRP_CN)   | out_full["é …ç›®_ja"].str.match(MSRP_JA_RE,   na=False)
is_dealer = out_full["é …ç›®"].isin(PRICE_ITEM_DEALER_CN) | out_full["é …ç›®_ja"].str.match(DEALER_JA_RE, na=False)

for col in out_full.columns[4:]:
    out_full.loc[is_msrp,  col] = out_full.loc[is_msrp,  col].map(lambda s: msrp_to_yuan_and_jpy(s, EXRATE_CNY_TO_JPY))
    out_full.loc[is_dealer, col] = out_full.loc[is_dealer, col].map(lambda s: dealer_to_yuan_only(s))

# ===== å€¤ã‚»ãƒ«ç¿»è¨³ï¼ˆä¾¡æ ¼è¡Œé™¤å¤–ï¼‰ =====
if TRANSLATE_VALUES:
    numeric_like = re.compile(r"^[\d\.\,\%\:/xX\+\-\(\)~ï½\smmkKwWhHVVAhLä¸¨Â·â€”â€“]+$")
    zh_char = re.compile(r"[\u4e00-\u9fff]")
    non_price_mask = ~(is_msrp | is_dealer)

    values_to_translate: List[str] = []
    coords_to_update: List[tuple] = []

    if enable_reuse and prev_cn_df.shape == df.shape and list(prev_cn_df.columns) == list(df.columns):
        diff_mask = (df != prev_cn_df)
        for i in range(len(df)):
            if not non_price_mask.iloc[i]:
                continue
            for j in range(4, len(df.columns)):
                cur = str(df.iat[i, j]).strip()
                if cur in {"", "â—", "â—‹", "â€“", "-", "â€”"}:
                    continue
                if numeric_like.fullmatch(cur):
                    continue

                need = diff_mask.iat[i, j]
                prev_cn = str(prev_cn_df.iat[i, j]).strip()
                prev_ja = str(prev_ja_df.iat[i, j]).strip()

                # å·®åˆ†ãŒç„¡ãã¦ã‚‚ã€å‰å›JA=CN/ç©º/ä¸­å›½èªå«ã¿ â†’ ç¿»è¨³å¯¾è±¡
                if not need and (prev_ja == "" or prev_ja == prev_cn or zh_char.search(prev_ja)):
                    need = True

                # ä»Šå›ã‚»ãƒ«è‡ªä½“ãŒä¸­å›½èªå«ã¿ â†’ å¼·åˆ¶ç¿»è¨³
                if zh_char.search(cur):
                    need = True

                if need:
                    values_to_translate.append(cur)
                    coords_to_update.append((i, j))
                else:
                    out_full.iat[i, j] = prev_ja_df.iat[i, j]
    else:
        for i in range(len(df)):
            if not non_price_mask.iloc[i]:
                continue
            for j in range(4, len(df.columns)):
                v = str(df.iat[i, j]).strip()
                if v in {"", "â—", "â—‹", "â€“", "-", "â€”"}:
                    continue
                if numeric_like.fullmatch(v):
                    continue
                if re.search(r"[\u4e00-\u9fff]", v):
                    values_to_translate.append(v)
                    coords_to_update.append((i, j))

    if values_to_translate:
        if not API_KEY.strip():
            print("âš  OPENAI_API_KEY ãŒæœªè¨­å®šã®ãŸã‚ã€å€¤ã‚»ãƒ«ç¿»è¨³ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸï¼ˆä¾¡æ ¼æ•´å½¢ã¯é©ç”¨æ¸ˆã¿ï¼‰ã€‚")
        else:
            tr = Translator(MODEL, API_KEY)
            uniq_vals = uniq(values_to_translate)
            val_map = tr.translate_values(uniq_vals)
            for (i, j), cn in zip(coords_to_update, values_to_translate):
                out_full.iat[i, j] = val_map.get(cn, cn)

# ===== ä¿å­˜ï¼ˆCSVã®æ¬ è½å¯¾ç­–ï¼šã‚¯ã‚©ãƒ¼ãƒˆï¼†BOMä»˜ãï¼‰ =====
out_full.to_csv(DST_PRIMARY, index=False,
                quoting=csv.QUOTE_MINIMAL, lineterminator="\n", encoding="utf-8-sig")
out_full.to_csv(DST_SECONDARY, index=False,
                quoting=csv.QUOTE_MINIMAL, lineterminator="\n", encoding="utf-8-sig")

# ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ï¼ˆå†åˆ©ç”¨ç”¨ï¼‰
df.to_csv(prev_cn_path, index=False,
          quoting=csv.QUOTE_MINIMAL, lineterminator="\n", encoding="utf-8-sig")
out_full.to_csv(prev_ja_path, index=False,
                quoting=csv.QUOTE_MINIMAL, lineterminator="\n", encoding="utf-8-sig")

print(f"âœ… Saved: {DST_PRIMARY}")
print(f"âœ… Saved (alt): {DST_SECONDARY}")
print(f"ğŸ“¦ Repo cache CN: {prev_cn_path}")
print(f"ğŸ“¦ Repo cache JA: {prev_ja_path}")
