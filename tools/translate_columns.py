from __future__ import annotations
import os, json, time, re, urllib.request
from pathlib import Path
import pandas as pd
from openai import OpenAI

# ====== å…¥å‡ºåŠ› ======
SERIES_ID = os.environ.get("SERIES_ID", "").strip()

def resolve_src_dst():
    csv_in  = os.environ.get("CSV_IN", "").strip()
    csv_out = os.environ.get("CSV_OUT", "").strip()

    def guess_paths_from_series(sid: str):
        if not sid:
            return None, None
        base = f"output/autohome/{sid}/config_{sid}"
        return Path(f"{base}.csv"), Path(f"{base}.ja.csv")

    default_in  = Path("output/autohome/7578/config_7578.csv")
    default_out = Path("output/autohome/7578/config_7578.ja.csv")

    src = Path(csv_in)  if csv_in  else None
    dst = Path(csv_out) if csv_out else None

    if src is None or dst is None:
        s2, d2 = guess_paths_from_series(SERIES_ID)
        src = src or s2
        dst = dst or d2

    src = src or default_in
    dst = dst or default_out
    return src, dst

SRC, DST_PRIMARY = resolve_src_dst()

def make_secondary(dst: Path) -> Path:
    s = dst.name
    if s.endswith(".ja.csv"):
        s2 = s.replace(".ja.csv", "_ja.csv")
    elif s.endswith("_ja.csv"):
        s2 = s.replace("_ja.csv", ".ja.csv")
    else:
        s2 = dst.stem + ".ja.csv"
    return dst.parent / s2

DST_SECONDARY = make_secondary(DST_PRIMARY)

# ====== è¨­å®š ======
MODEL   = os.environ.get("OPENAI_MODEL", "gpt-4.1-mini")
API_KEY = os.environ.get("OPENAI_API_KEY")

TRANSLATE_VALUES   = os.environ.get("TRANSLATE_VALUES", "true").lower() == "true"
TRANSLATE_COLNAMES = os.environ.get("TRANSLATE_COLNAMES", "true").lower() == "true"
STRIP_GRADE_PREFIX = os.environ.get("STRIP_GRADE_PREFIX", "true").lower() == "true"
SERIES_PREFIX_RE   = os.environ.get("SERIES_PREFIX", "").strip()
EXRATE_CNY_TO_JPY  = float(os.environ.get("EXRATE_CNY_TO_JPY", "21.0"))

BATCH_SIZE, RETRIES, SLEEP_BASE = 60, 3, 1.2

# ====== ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆè‡ªå‹•å–å¾—ï¼ˆãƒ¬ãƒ¼ãƒˆæ–¹å‘ã‚’è‡ªå‹•è£œæ­£ï¼‰ ======
def _fetch_json(url: str, timeout: float = 6.0):
    with urllib.request.urlopen(url, timeout=timeout) as r:
        return json.loads(r.read().decode("utf-8"))

def get_cny_jpy_rate_fallback(default_rate: float) -> float:
    rate = None
    try:
        data = _fetch_json("https://api.frankfurter.dev/latest?from=CNY&to=JPY")
        rate = float(data["rates"]["JPY"])
        print(f"ğŸ’± Frankfurter raw: {rate}")
    except Exception:
        pass
    if not rate:
        try:
            data = _fetch_json("https://api.exchangerate.host/latest?base=CNY&symbols=JPY")
            rate = float(data["rates"]["JPY"])
            print(f"ğŸ’± exchangerate.host raw: {rate}")
        except Exception:
            pass
    if not rate:
        print(f"âš ï¸ Using fallback rate {default_rate}")
        return float(default_rate)
    # æ–¹å‘è£œæ­£ï¼ˆ1CNYã‚ãŸã‚Šã®JPYå€¤ãŒ1æœªæº€ã®å ´åˆã¯é€†æ•°ã‚’å–ã‚‹ï¼‰
    if rate < 1:
        rate = 1 / rate
        print(f"â†”ï¸ rate inverted to {rate}")
    return rate

EXRATE_CNY_TO_JPY = get_cny_jpy_rate_fallback(EXRATE_CNY_TO_JPY)

# ====== å›ºå®šè¨³ãƒ»æ­£è¦åŒ– ======
NOISE_ANY = ["å¯¹æ¯”","å‚æ•°","å›¾ç‰‡","é…ç½®","è¯¦æƒ…"]
NOISE_PRICE_TAIL = ["è¯¢ä»·","è®¡ç®—å™¨","è¯¢åº•ä»·","æŠ¥ä»·","ä»·æ ¼è¯¢é—®","èµ·","èµ·å”®","åˆ°åº—","ç»é”€å•†"]

def clean_any_noise(s:str)->str:
    s=str(s) if s is not None else ""
    for w in NOISE_ANY+NOISE_PRICE_TAIL:
        s=s.replace(w,"")
    return re.sub(r"\s+"," ",s).strip(" ã€€-â€”â€“")

def clean_price_cell(s:str)->str:
    t=clean_any_noise(s)
    for w in NOISE_PRICE_TAIL:
        t=re.sub(rf"(?:\s*{re.escape(w)}\s*)+$","",t)
    return t.strip()

RE_PAREN_ANY_YEN=re.compile(r"ï¼ˆ[^ï¼‰]*(?:æ—¥æœ¬å††|JPY|[Â¥ï¿¥]|å††)[^ï¼‰]*ï¼‰")
RE_ANY_YEN_TOKEN=re.compile(r"(æ—¥æœ¬å††|JPY|[Â¥ï¿¥]|å††)")
def strip_any_yen_tokens(s:str)->str:
    t=str(s)
    t=RE_PAREN_ANY_YEN.sub("",t)
    t=RE_ANY_YEN_TOKEN.sub("",t)
    return re.sub(r"\s+"," ",t).strip()

BRAND_MAP={
    "BYD":"BYD","æ¯”äºšè¿ª":"BYD",
    "å¥”é©°":"ãƒ¡ãƒ«ã‚»ãƒ‡ã‚¹ãƒ»ãƒ™ãƒ³ãƒ„","æ¢…èµ›å¾·æ–¯-å¥”é©°":"ãƒ¡ãƒ«ã‚»ãƒ‡ã‚¹ãƒ»ãƒ™ãƒ³ãƒ„",
}

FIX_JA_ITEMS={
    "å‚å•†æŒ‡å¯¼ä»·":"ãƒ¡ãƒ¼ã‚«ãƒ¼å¸Œæœ›å°å£²ä¾¡æ ¼",
    "ç»é”€å•†å‚è€ƒä»·":"ãƒ‡ã‚£ãƒ¼ãƒ©ãƒ¼è²©å£²ä¾¡æ ¼ï¼ˆå…ƒï¼‰",
    "ç»é”€å•†æŠ¥ä»·":"ãƒ‡ã‚£ãƒ¼ãƒ©ãƒ¼è²©å£²ä¾¡æ ¼ï¼ˆå…ƒï¼‰",
    "ç»é”€å•†":"ãƒ‡ã‚£ãƒ¼ãƒ©ãƒ¼è²©å£²ä¾¡æ ¼ï¼ˆå…ƒï¼‰",
    "è¢«åŠ¨å®‰å…¨":"è¡çªå®‰å…¨",
}
FIX_JA_SECTIONS={"è¢«åŠ¨å®‰å…¨":"è¡çªå®‰å…¨"}

PRICE_ITEM_MSRP_CN={"å‚å•†æŒ‡å¯¼ä»·"}
PRICE_ITEM_DEALER_CN={"ç»é”€å•†å‚è€ƒä»·","ç»é”€å•†æŠ¥ä»·","ç»é”€å•†"}

# ====== é‡‘é¡æ•´å½¢ï¼ˆä¸‡å…ƒâ†’å…ƒâ†’å††ï¼‰ ======
RE_WAN=re.compile(r"(?P<num>\d+(?:\.\d+)?)\s*ä¸‡")
RE_YUAN=re.compile(r"(?P<num>[\d,]+)\s*å…ƒ")

def parse_cny(text:str):
    t=str(text)
    m1=RE_WAN.search(t)
    if m1:return float(m1.group("num"))*10000.0
    m2=RE_YUAN.search(t)
    if m2:return float(m2.group("num").replace(",",""))
    return None

def msrp_to_yuan_and_jpy(cell:str,rate:float)->str:
    t=strip_any_yen_tokens(clean_price_cell(cell))
    if not t or t in {"-","â€“","â€”"}:return t
    cny=parse_cny(t)
    if cny is None:
        if("å…ƒ"not in t)and RE_WAN.search(t):t=f"{t}å…ƒ"
        return t
    m1=RE_WAN.search(t)
    yuan_disp=f"{m1.group('num')}ä¸‡å…ƒ" if m1 else (t if"å…ƒ"in t else f"{t}å…ƒ")
    jpy=int(round(cny*rate))
    return f"{yuan_disp}ï¼ˆæ—¥æœ¬å††{jpy:,}å††ï¼‰"

def dealer_to_yuan_only(cell:str)->str:
    t=strip_any_yen_tokens(clean_price_cell(cell))
    if not t or t in {"-","â€“","â€”"}:return t
    if("å…ƒ"not in t)and RE_WAN.search(t):t=f"{t}å…ƒ"
    return t

# ====== Translator ä»–ï¼ˆç•¥ï¼‰ ======
# ï¼ˆä»¥é™ã¯ã‚ãªãŸã®ç¾è¡Œæ­£å¸¸ç‰ˆã¨åŒä¸€ã€æ”¹å¤‰ãªã—ï¼‰

# ...ï¼ˆæ—¢å­˜ã® Translator, uniq, chunked, grade_rule_ja ç­‰ã¯ãã®ã¾ã¾ï¼‰...
