# -*- coding: utf-8 -*-
"""
Autohome ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å–å¾—ã—ã€ç¢ºå®Ÿã« image_url ã‚’åŸ‹ã‚ã‚‹ç‰ˆ
- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å®Œäº†å¾Œã«å¾…æ©Ÿã‚’å…¥ã‚Œã¦ lazy-load è§£æ±º
- ç”»åƒURLã¯ data-src/data-original/srcset/src ã®å„ªå…ˆé †ã§æŠ½å‡º
- ãã‚Œã§ã‚‚ç©ºãªã‚‰è©³ç´°ãƒšãƒ¼ã‚¸(ã‚·ãƒªãƒ¼ã‚ºURL)ã® og:image ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å–å¾—
- å‡ºåŠ›: public/autohome_ranking_with_image_urls.csv

ä¾å­˜:
  pip install playwright pandas
  python -m playwright install chromium
"""

import asyncio
import re
import time
from pathlib import Path

import pandas as pd
from playwright.async_api import async_playwright

RANK_URL = "https://www.autohome.com.cn/rank/1"
TARGET_COUNT = 100  # 100ä½ã¾ã§
OUT_CSV = Path("public/autohome_ranking_with_image_urls.csv")

# ---- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----

def parse_srcset(srcset: str) -> str:
    """srcset ã‹ã‚‰æœ€å¤§è§£åƒåº¦ã® URL ã‚’è¿”ã™"""
    if not srcset:
        return ""
    # "url1 1x, url2 2x" or "url1 320w, url2 640w"
    cand = []
    for part in srcset.split(","):
        part = part.strip()
        if not part:
            continue
        m = re.match(r"(\S+)\s+(\d+)(w|x)", part)
        if m:
            url = m.group(1)
            val = int(m.group(2))
            cand.append((val, url))
        else:
            # å˜ç‹¬URLã ã‘ã®ã‚±ãƒ¼ã‚¹
            if part.startswith("http"):
                cand.append((1, part.split()[0]))
    if not cand:
        return ""
    cand.sort(key=lambda x: x[0], reverse=True)
    return cand[0][1]

async def get_og_image_from_detail(ctx, url: str) -> str:
    """è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰ og:image ã‚’æ‹¾ã†ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        # request çµŒç”±ã§ HTML ã‚’å–ã£ã¦ãƒ‘ãƒ¼ã‚¹ï¼ˆæç”»ã—ãªã„ã®ã§é€Ÿã„ï¼‰
        r = await ctx.request.get(url, timeout=30000, headers={
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
            "Referer": "https://www.autohome.com.cn/",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        })
        if r.ok:
            html = await r.text()
            m = re.search(r'<meta\s+property=["\']og:image["\']\s+content=["\']([^"\']+)["\']', html, re.I)
            if m:
                og = m.group(1)
                if og.startswith("http"):
                    return og
    except Exception:
        pass
    return ""

async def scroll_to_load(page, want_count=TARGET_COUNT):
    """100ä½ã¾ã§èª­ã¿è¾¼ã¾ã‚Œã‚‹ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã€‚æ¯å›å¾…æ©Ÿã‚’å…¥ã‚Œã¦ lazy-load ã‚’è§£æ¶ˆ"""
    seen = 0
    last_inc = time.time()
    while True:
        # ä¸‹ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
        await page.evaluate("""
            () => { window.scrollTo(0, document.body.scrollHeight); }
        """)
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¾…ã¡
        await page.wait_for_load_state("domcontentloaded")
        # ç”»åƒã® lazy è§£æ±ºæ™‚é–“ã‚’ä¸ãˆã‚‹
        await page.wait_for_timeout(1200)

        # ç¾åœ¨ã®ä»¶æ•°ã‚’ page å´ã§æ•°ãˆã‚‹ï¼ˆã‚¢ã‚¤ãƒ†ãƒ ã®ã‚»ãƒ¬ã‚¯ã‚¿ã¯ç·©ã‚ã«ï¼‰
        count = await page.evaluate("""
            () => {
              const cards = document.querySelectorAll('[data-rank-item], .athm-rank__item, li, .tw-flex, .tw-card');
              // è»Šã‚·ãƒªãƒ¼ã‚ºãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯ã£ã½ã„ a ã‚’æ•°ãˆã‚‹
              let n = 0;
              cards.forEach(c => {
                const a = c.querySelector('a[href^="https://www.autohome.com.cn/"]');
                if (a && /https:\/\/www\.autohome\.com\.cn\/\d+\/?$/.test(a.href)) n++;
              });
              return n;
            }
        """)
        if count > seen:
            seen = count
            last_inc = time.time()

        if seen >= want_count:
            break

        # ä¸€å®šæ™‚é–“å¢—ãˆãªã‘ã‚Œã°çµ‚äº†ï¼ˆå®‰å…¨å¼ï¼‰
        if time.time() - last_inc > 5:
            break

async def extract_rows(page, ctx):
    """ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡Œã‚’æŠ½å‡ºã€‚ç”»åƒURLã¯å„ªå…ˆé †ï¼‹è©³ç´°ãƒšãƒ¼ã‚¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§åŸ‹ã‚ã‚‹"""
    rows = await page.evaluate("""
        () => {
          // ç·©ã‚ã«å…¨ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ‹¾ã„ã€å¿…è¦æƒ…å ±ãŒæƒã†ã‚‚ã®ã«çµã‚‹
          const nodes = Array.from(document.querySelectorAll('[data-rank-item], .athm-rank__item, li, .tw-flex, .tw-card'));
          const arr = [];
          let rankCounter = 0;
          for (const n of nodes) {
            const a = n.querySelector('a[href^="https://www.autohome.com.cn/"]');
            if (!a) continue;
            const href = a.href;
            if (!/^https:\/\/www\.autohome\.com\.cn\/\d+\/?$/.test(href)) continue;

            // rankï¼ˆè¦‹å‡ºã—ã‚„æ•°å­—ã‚’æ‹¾ã†ã€‚ãªã‘ã‚Œã°ã‚«ã‚¦ãƒ³ã‚¿ï¼‰
            let rankTxt = "";
            const rankEl = n.querySelector('.rank, .tw-rank, [data-rank], .athm-rank__num, .tw-text-\\[\\#FF5500\\]');
            if (rankEl) rankTxt = rankEl.textContent.trim();
            if (!rankTxt) {
              rankCounter += 1;
              rankTxt = String(rankCounter);
            }

            // name / titleï¼ˆè»Šåï¼‰
            let title = "";
            const nameEl = n.querySelector('h3, h4, .name, .tw-text-base, .tw-font-semibold, .athm-rank__title');
            if (nameEl) title = nameEl.textContent.trim();

            // ç”»åƒã‚¿ã‚°
            const img = n.querySelector('img');
            let src = "", dataSrc = "", dataOriginal = "", srcset = "", dataSrcset = "";
            if (img) {
              src = img.getAttribute('src') || "";
              dataSrc = img.getAttribute('data-src') || "";
              dataOriginal = img.getAttribute('data-original') || "";
              srcset = img.getAttribute('srcset') || "";
              dataSrcset = img.getAttribute('data-srcset') || "";
            }

            arr.push({
              rank: rankTxt,
              name: title,
              url: href,
              img_src: src,
              img_data_src: dataSrc,
              img_data_original: dataOriginal,
              img_srcset: srcset,
              img_data_srcset: dataSrcset,
            });
          }
          return arr;
        }
    """)

    records = []
    for r in rows:
        # ç”»åƒURLã®å„ªå…ˆé †ä½
        cand = [
            r.get("img_data_src") or "",
            r.get("img_data_original") or "",
        ]
        # srcset ç³»ã‚’è§£æã—ã¦æœ€å¤§è§£åƒåº¦ã‚’æ‹¾ã†ãŸã‚ã€ã“ã“ã§ã¯ãƒ€ãƒŸãƒ¼ãƒ»å®Ÿå‡¦ç†ã¯Pythonå´
        cand.append(r.get("img_data_srcset") or "")
        cand.append(r.get("img_srcset") or "")
        cand.append(r.get("img_src") or "")

        # srcset ã‚’å±•é–‹
        final = ""
        for c in cand:
            if not c:
                continue
            if " " in c and ("," in c or c.strip().endswith(("w","x"))):
                # srcset é¢¨å‘³
                parsed = parse_srcset(c)
                if parsed:
                    final = parsed
                    break
            else:
                final = c
                break

        # data:imageï¼ˆBase64ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰ã‚„ç©ºã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if (not final) or final.startswith("data:image"):
            og = await get_og_image_from_detail(ctx, r["url"])
            if og:
                final = og

        records.append({
            "rank": r.get("rank"),
            "name": r.get("name"),
            "url": r.get("url"),
            "image_url": final,
        })
    return records

async def main():
    OUT_CSV.parent.mkdir(parents=True, exist_ok=True)
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        ctx = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
        )
        page = await ctx.new_page()

        print(f"ğŸŒ Visiting: {RANK_URL}")
        await page.goto(RANK_URL, wait_until="domcontentloaded", timeout=60000)

        # 100ä½ã¾ã§èª­ã¿è¾¼ã¿ï¼ˆlazy-loadå¾…ã¡ã‚’å«ã‚€ï¼‰
        print(f"ğŸ”„ Scrolling until {TARGET_COUNT}th rank loaded...")
        await scroll_to_load(page, want_count=TARGET_COUNT)

        rows = await extract_rows(page, ctx)
        # ä¸‡ä¸€ 100 æœªæº€ãªã‚‰ã€ãã®æ™‚ç‚¹ã§çµ‚äº†
        if not rows:
            print("âŒ No rows extracted.")
            await browser.close()
            return

        # DataFrame ã«ã—ã¦ä¿å­˜
        df = pd.DataFrame(rows)
        # rank ã‚’æ•°å€¤ã«ã—ã¦ã‚½ãƒ¼ãƒˆï¼ˆä¿é™ºï¼‰
        with pd.option_context('mode.chained_assignment', None):
            df["rank_num"] = pd.to_numeric(df["rank"], errors="coerce")
        df = df.sort_values(by=["rank_num", "rank"], ascending=True).drop(columns=["rank_num"])
        OUT_CSV.parent.mkdir(parents=True, exist_ok=True)
        df.to_csv(OUT_CSV, index=False, encoding="utf-8-sig")
        print(f"âœ… Done. Saved â†’ {OUT_CSV}")

        await browser.close()

if __name__ == "__main__":
    asyncio.run(main())
