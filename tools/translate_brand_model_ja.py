#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
translate_brand_model_ja.py
- å…¥åŠ›CSVï¼ˆbrand, model, title_raw ãŒã‚ã‚‹å‰æï¼‰ã‚’èª­ã¿è¾¼ã¿
- brand ã¨ model ã‚’æ—¥æœ¬èªžè¨³ã—ã€brand_ja / model_ja ã‚’åˆ—è¿½åŠ ã—ã¦ä¿å­˜
- ã¾ãšãƒ«ãƒ¼ãƒ«ã§ã€Œè‹±å­—ã¯ãã®ã¾ã¾ã€ã€Œè¨˜å·ã¯ä¿æŒã€ã€ãã‚Œä»¥å¤–ã¯ LLM ç¿»è¨³
- ä½Žã‚³ã‚¹ãƒˆåŒ–ã®ãŸã‚ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚ã‚Šï¼ˆtools/.cache_ja.jsonï¼‰

ä½¿ã„æ–¹:
  python tools/translate_brand_model_ja.py \
    --input  data/autohome_raw_2025-09_with_brand.csv \
    --output data/autohome_raw_2025-09_with_brand_ja.csv \
    --model  gpt-4o-mini
"""

import os, re, json, time, argparse
from pathlib import Path
import pandas as pd

CACHE_PATH = Path("tools/.cache_ja.json")

# --- ã¡ã‚‡ã„ãƒ«ãƒ¼ãƒ« -------------------------------------------------------------

def looks_latin_or_mixed(s: str) -> bool:
    """è‹±æ•°å­—/è¨˜å·ãƒ¡ã‚¤ãƒ³ãªã‚‰ Trueï¼ˆTesla, Model Y, SU7 ãªã©ã¯ãã®ã¾ã¾ï¼‰"""
    if not s:
        return False
    # ä¸­/æ—¥/éŸ“ã®æ–‡å­—ãŒç„¡ã„ or ã»ã¼è‹±æ•°å­—ãªã‚‰ True
    return not re.search(r"[\u4e00-\u9fff\u3040-\u30ff]", s) or re.fullmatch(r"[A-Za-z0-9\-\s_+./]+", s) is not None

# ä¸€éƒ¨ãƒ–ãƒ©ãƒ³ãƒ‰ã®ç°¡æ˜“å›ºå®šè¨³ï¼ˆå¿…è¦æœ€ä½Žé™ãƒ»å¥½ã¿ã§æ‹¡å¼µå¯ï¼‰
FIXED_BRAND = {
    "ç‰¹æ–¯æ‹‰": "ãƒ†ã‚¹ãƒ©",
    "ä¸°ç”°": "ãƒˆãƒ¨ã‚¿",
    "æœ¬ç”°": "ãƒ›ãƒ³ãƒ€",
    "æ—¥äº§": "æ—¥ç”£",
    "å¤§ä¼—": "ãƒ•ã‚©ãƒ«ã‚¯ã‚¹ãƒ¯ãƒ¼ã‚²ãƒ³",
    "å¥¥è¿ª": "ã‚¢ã‚¦ãƒ‡ã‚£",
    "å®é©¬": "BMW",
    "å¥”é©°": "ãƒ¡ãƒ«ã‚»ãƒ‡ã‚¹ãƒ»ãƒ™ãƒ³ãƒ„",
    "æ¯”äºšè¿ª": "BYD",
    "å‰åˆ©": "ã‚¸ãƒ¼ãƒªãƒ¼",
    "å‰åˆ©æ±½è½¦": "ã‚¸ãƒ¼ãƒªãƒ¼",
    "äº”è±": "ã‚¦ãƒ¼ãƒªãƒ³",
    "ä¸Šæ±½å¤§ä¼—": "SAIC-VW",
    "å¹¿æ±½ä¸°ç”°": "GACãƒˆãƒ¨ã‚¿",
    "é•¿å®‰": "é•·å®‰",
    "å¥‡ç‘ž": "å¥‡ç‘ž",
    "å°ç±³": "ã‚·ãƒ£ã‚ªãƒŸ",
    "çº¢æ——": "ç´…æ——",
    "åˆ«å…‹": "ãƒ“ãƒ¥ã‚¤ãƒƒã‚¯",
    "åˆ«å…‹æ±½è½¦": "ãƒ“ãƒ¥ã‚¤ãƒƒã‚¯",
}

# --- LLM ----------------------------------------------------------------------

def llm_translate_pairs(pairs, model="gpt-4o-mini"):
    """
    pairs: [{"brand": "...", "model": "...", "title": "..."} ...]
    ã¾ã¨ã‚ã¦1å›žã§æŠ•ã’ã€JSONé…åˆ—ã§è¿”ã•ã›ã‚‹ï¼ˆå‡ºåŠ›ã‚’åŽ³å¯†JSONã«é™å®šï¼‰
    """
    from openai import OpenAI
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼šè‡ªå‹•è»Šã®æ–‡è„ˆã§è‡ªç„¶ãªæ—¥æœ¬èªžã«ã€‚è‹±å­—ã¯ç¶­æŒã€æ•°å­—/è¨˜å·ã‚‚ä¿æŒã€‚
    sys = (
        "ã‚ãªãŸã¯è‡ªå‹•è»Šåã®ç¿»è¨³å™¨ã§ã™ã€‚å…¥åŠ›ã¯ä¸­å›½èªžä¸­å¿ƒã®ãƒ–ãƒ©ãƒ³ãƒ‰åã¨è»Šç¨®åã®çµ„ã§ã™ã€‚"
        "ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã§æ—¥æœ¬èªžã¸å¤‰æ›ã—ã¦ãã ã•ã„ï¼š\n"
        "1) è‹±å­—ã‚„æ•°å­—ã€åž‹ç•ªï¼ˆä¾‹: Model Y, SU7, A6Lï¼‰ã¯ãã®ã¾ã¾æ®‹ã™\n"
        "2) ãƒ–ãƒ©ãƒ³ãƒ‰ã¯æ—¢çŸ¥ã®æ—¥æœ¬èªžè¡¨è¨˜ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã†ã€‚ãªã‘ã‚Œã°ã‚«ã‚¿ã‚«ãƒŠéŸ³è¨³\n"
        "3) è»Šç¨®ã¯è‡ªç„¶ãªæ—¥æœ¬èªžï¼ˆå¤šãã¯ã‚«ã‚¿ã‚«ãƒŠã€ãŸã ã— 'æ˜Ÿè¶ŠL' ã® L ãªã©è‹±å­—ã¯ä¿æŒï¼‰\n"
        "4) å‡ºåŠ›ã¯åŽ³å¯†ãªJSONé…åˆ—ã€‚å„è¦ç´ ã¯ {\"brand_ja\":\"â€¦\",\"model_ja\":\"â€¦\"} ã®ã¿\n"
        "5) ä½™è¨ˆãªèª¬æ˜Žã‚„ã‚³ãƒ¡ãƒ³ãƒˆã¯ç¦æ­¢"
    )
    user_lines = []
    for i, p in enumerate(pairs, 1):
        user_lines.append(f"{i}. brand={p['brand']} | model={p['model']} | title={p.get('title','')}")
    user = "\n".join(user_lines)

    resp = client.chat.completions.create(
        model=model,
        temperature=0,
        messages=[
            {"role": "system", "content": sys},
            {"role": "user", "content": user},
        ],
    )
    txt = (resp.choices[0].message.content or "").strip()
    m = re.search(r"\[.*\]", txt, re.S)
    if not m:
        return []
    try:
        arr = json.loads(m.group(0))
        return arr if isinstance(arr, list) else []
    except Exception:
        return []

# --- ãƒ¡ã‚¤ãƒ³ --------------------------------------------------------------------

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--input", required=True)
    ap.add_argument("--output", required=True)
    ap.add_argument("--model", default="gpt-4o-mini")
    ap.add_argument("--batch-size", type=int, default=10)
    ap.add_argument("--sleep-ms", type=int, default=150)
    args = ap.parse_args()

    if not os.getenv("OPENAI_API_KEY"):
        raise SystemExit("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")

    df = pd.read_csv(args.input)

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    cache = {}
    if CACHE_PATH.exists():
        try:
            cache = json.loads(CACHE_PATH.read_text(encoding="utf-8"))
        except Exception:
            cache = {}
    changed = False

    out_brand_ja, out_model_ja = [], []

    batch = []
    idx_map = []  # ãƒãƒƒãƒâ†’è¡Œç•ªå·å¯¾å¿œ
    for i, row in df.iterrows():
        b = str(row.get("brand", "")).strip()
        m = str(row.get("model", "")).strip()
        t = str(row.get("title_raw", "")).strip()

        key = f"{b}|{m}"
        trans_b, trans_m = None, None

        # 1) å›ºå®šè¨³ãƒ»è‹±å­—å„ªå…ˆã®ãƒ«ãƒ¼ãƒ«
        if looks_latin_or_mixed(b):
            trans_b = b
        elif b in FIXED_BRAND:
            trans_b = FIXED_BRAND[b]

        if looks_latin_or_mixed(m):
            trans_m = m

        # 2) ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        if key in cache:
            cached = cache[key]
            # ãƒ«ãƒ¼ãƒ«ã§æ±ºã¾ã£ã¦ã„ãªã„å´ã ã‘ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰è£œã†
            if trans_b is None:
                trans_b = cached.get("brand_ja") or trans_b
            if trans_m is None:
                trans_m = cached.get("model_ja") or trans_m

        # 3) ã¾ã æ¬ ã‘ã¦ã„ã‚‹å ´åˆã¯å¾Œã§LLMã¸
        if trans_b is None or trans_m is None:
            batch.append({"brand": b, "model": m, "title": t})
            idx_map.append(i)
            # ã™ãåŸ‹ã‚ã‚‹ã®ã¯å¾Œã§
            out_brand_ja.append(None)
            out_model_ja.append(None)
        else:
            out_brand_ja.append(trans_b)
            out_model_ja.append(trans_m)

        # ãƒãƒƒãƒæŠ•ã’
        if len(batch) >= args.batch_size:
            res = llm_translate_pairs(batch, model=args.model)
            for k, ridx in enumerate(idx_map):
                if k < len(res):
                    tb = res[k].get("brand_ja", "") or ""
                    tm = res[k].get("model_ja", "") or ""
                    out_brand_ja[ridx] = out_brand_ja[ridx] or tb
                    out_model_ja[ridx] = out_model_ja[ridx] or tm
                    cache_key = f"{df.at[ridx,'brand']}|{df.at[ridx,'model']}"
                    cache[cache_key] = {"brand_ja": out_brand_ja[ridx], "model_ja": out_model_ja[ridx]}
                    changed = True
            batch.clear()
            idx_map.clear()
            time.sleep(args.sleep_ms/1000.0)

    # æœ€çµ‚ãƒãƒƒãƒ
    if batch:
        res = llm_translate_pairs(batch, model=args.model)
        for k, ridx in enumerate(idx_map):
            if k < len(res):
                tb = res[k].get("brand_ja", "") or ""
                tm = res[k].get("model_ja", "") or ""
                out_brand_ja[ridx] = out_brand_ja[ridx] or tb
                out_model_ja[ridx] = out_model_ja[ridx] or tm
                cache_key = f"{df.at[ridx,'brand']}|{df.at[ridx,'model']}"
                cache[cache_key] = {"brand_ja": out_brand_ja[ridx], "model_ja": out_model_ja[ridx]}
                changed = True
        batch.clear()
        idx_map.clear()

    # æ¬ ã‘ã¦ã„ã‚Œã°æœ€å¾Œã«åŸ‹ã‚ã‚‹ï¼ˆå®‰å…¨ç­–ï¼‰
    for i in range(len(df)):
        if out_brand_ja[i] is None:
            out_brand_ja[i] = str(df.at[i, "brand"])
        if out_model_ja[i] is None:
            out_model_ja[i] = str(df.at[i, "model"])

    df_out = df.copy()
    df_out["brand_ja"] = out_brand_ja
    df_out["model_ja"] = out_model_ja
    df_out.to_csv(args.output, index=False, encoding="utf-8-sig")
    print(f"âœ… ä¿å­˜: {args.output}")

    if changed:
        CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)
        CACHE_PATH.write_text(json.dumps(cache, ensure_ascii=False, indent=2), encoding="utf-8")
        print(f"ðŸ—‚ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°: {CACHE_PATH}")

if __name__ == "__main__":
    main()
